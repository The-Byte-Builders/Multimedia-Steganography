{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4811,"status":"ok","timestamp":1677756442836,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"},"user_tz":-345},"id":"ZRG0HrYFnBOz","outputId":"de4a2731-a326-4e72-c2a8-21fffe61db3d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# yo chai ho hai\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6582,"status":"ok","timestamp":1677756449414,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"},"user_tz":-345},"id":"eQA2DiaCSlGw","outputId":"3b007584-afab-4d24-a81a-eb3128b31450"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_wavelets\n","  Cloning https://github.com/fbcotter/pytorch_wavelets to /tmp/pip-install-uajb8e2l/pytorch-wavelets_aa81b8f012934f0ab785622a400e83e2\n","  Running command git clone --filter=blob:none --quiet https://github.com/fbcotter/pytorch_wavelets /tmp/pip-install-uajb8e2l/pytorch-wavelets_aa81b8f012934f0ab785622a400e83e2\n","  Resolved https://github.com/fbcotter/pytorch_wavelets to commit 9a0c507f04f43c5397e384bb6be8340169b2fd9a\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from pytorch_wavelets) (1.22.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from pytorch_wavelets) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from pytorch_wavelets) (1.13.1+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch->pytorch_wavelets) (4.5.0)\n","Building wheels for collected packages: pytorch_wavelets\n","  Building wheel for pytorch_wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytorch_wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54869 sha256=cfe7e3c08ad8ce26255b534ae18af7ce15c58d0bc76f3eac15c57d72aee766d7\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-ec3yq77b/wheels/0c/15/77/b39e24755082220b25f2d5b1bae3aa04bc4e1fc60056885daf\n","Successfully built pytorch_wavelets\n","Installing collected packages: pytorch_wavelets\n","Successfully installed pytorch_wavelets-1.3.0\n"]}],"source":["pip install git+https://github.com/fbcotter/pytorch_wavelets#egg=pytorch_wavelets"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"3or6R6we1LZV","executionInfo":{"status":"ok","timestamp":1677756453535,"user_tz":-345,"elapsed":4127,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np \n","import pandas as pd\n","import torchvision\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import joblib\n","from google.colab import drive\n","from pytorch_wavelets import DWTForward, DWTInverse # (or import DWT, IDWT)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"F0Dzeha0W7Jc","executionInfo":{"status":"ok","timestamp":1677756453536,"user_tz":-345,"elapsed":6,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["# img = Image.new(\"RGB\", (512, 512), (0, 0, 0))\n","\n","# # Save the image as a PNG file\n","# img.save(\"/content/drive/MyDrive/Colab Notebooks/Steganography/Black.png\")\n","# img = Image.new(\"RGB\", (512, 512), (255, 255, 255))\n","\n","# # Save the image as a PNG file\n","# img.save(\"/content/drive/MyDrive/Colab Notebooks/Steganography/White.png\")"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"dyJXE4JRxf46","executionInfo":{"status":"ok","timestamp":1677756453537,"user_tz":-345,"elapsed":7,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":8,"metadata":{"id":"SjRNavhWzFbG","executionInfo":{"status":"ok","timestamp":1677756453537,"user_tz":-345,"elapsed":6,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["# img = Image.open('/content/drive/MyDrive/Colab Notebooks/Steganography/Invert.png')\n","\n","# # Keep only the first 3 channels (red, green, and blue)\n","# img = img.convert('RGB')\n","\n","# # Save the converted 3-channel image\n","# img.save('/content/drive/MyDrive/Colab Notebooks/Steganography/Invert.png')\n","# img = Image.open('/content/drive/MyDrive/Colab Notebooks/Steganography/image.png')\n","\n","# # Keep only the first 3 channels (red, green, and blue)\n","# img = img.convert('RGB')\n","\n","# # Save the converted 3-channel image\n","# img.save('/content/drive/MyDrive/Colab Notebooks/Steganography/image.png')\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"H2R_S-By1s-L","executionInfo":{"status":"ok","timestamp":1677756453538,"user_tz":-345,"elapsed":7,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["root_dir = '/content/drive/MyDrive/Colab Notebooks/'\n","dataset_path = os.path.join(root_dir,'Dataset256')\n","\n","train_csv = os.path.join(root_dir,'Dataset_x256.csv')\n","test_csv = os.path.join(root_dir,'Steganography/validation_dataset.csv')\n","train_folder = os.path.join(dataset_path,'train')\n","validation_folder = os.path.join(dataset_path,'Valid')"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"CXAM3lgbcaOf","executionInfo":{"status":"ok","timestamp":1677756453538,"user_tz":-345,"elapsed":6,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["cover = '/content/drive/MyDrive/Colab Notebooks/Steganography/NikeshS.jpg'\n","secret = '/content/drive/MyDrive/Colab Notebooks/Steganography/NikeshC.jpg'\n","\n","dataset = [{\n","        'cover_image':cover,\n","        'secret_image':secret\n","    }]\n","dataframe = pd.DataFrame(dataset)\n","cover = Image.open(cover)\n","secret = Image.open(secret)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"JnMSTB4b1d6j","executionInfo":{"status":"ok","timestamp":1677756453539,"user_tz":-345,"elapsed":7,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"9w98z0qOpipP","executionInfo":{"status":"ok","timestamp":1677756453539,"user_tz":-345,"elapsed":7,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","IMG_SIZE = 256\n","LEARNING_RATE  = 0.001\n","COVER_LOSS_WEIGHT = 1\n","SECRET_LOSS_WEIGHT = 1\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 1\n","EPOCHS = 1000\n","DECODER_LOSS_WEIGHT = 1"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"H5b5sJ8W4TUJ","executionInfo":{"status":"ok","timestamp":1677756453987,"user_tz":-345,"elapsed":455,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["imagetransformation = {\n","    'train_transforms':torchvision.transforms.Compose([torchvision.transforms.ToTensor()]),\n","    'valid_transforms':torchvision.transforms.Compose([torchvision.transforms.ToTensor()]),\n","    # 'test_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize(cover.size),torchvision.transforms.ToTensor()])\n","}"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"4qYPcaAi6S6_","executionInfo":{"status":"ok","timestamp":1677756453988,"user_tz":-345,"elapsed":7,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["#conversion of image into resized format and return of trnasformed image\n","class SteganoDataset(torch.utils.data.Dataset):\n","    def __init__(self,dataset_csv,transforms,type_of_dataset,size='complete'):\n","        self.dataset = pd.read_csv(dataset_csv)\n","        # self.dataset = dataset_csv\n","        self.dataset = self.dataset.reset_index(drop=True)\n","        if size !='complete':\n","            self.dataset = self.dataset[:2]\n","        self.transforms = transforms\n","        self.type = type_of_dataset\n","    \n","    def __getitem__(self,index):\n","        cover_image = self.dataset.iloc[index]['cover_image']\n","        secret_image = self.dataset.iloc[index]['secret_image']\n","        cover_image = Image.open(os.path.join(dataset_path,'cover',cover_image))\n","        secret_image = Image.open(os.path.join(dataset_path,'secret',secret_image))\n","        transformed_cover_image = self.transforms(cover_image)\n","        transformed_secret_image = self.transforms(secret_image)\n","        return {\n","                'cover_image':transformed_cover_image,\n","                'secret_image':transformed_secret_image,\n","            }\n","        \n","    \n","    def __len__(self):\n","      return len(self.dataset)"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"pOHTdzOVQaYp","executionInfo":{"status":"ok","timestamp":1677756453988,"user_tz":-345,"elapsed":6,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["class PrepNetwork(nn.Module):\n","    def __init__(self,xfm):\n","        super().__init__()\n","        self.xfm = xfm\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn1 = nn.BatchNorm2d(6)\n","        self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn2 = nn.BatchNorm2d(12)\n","\n","        # Define activation functions\n","        self.relu = nn.ReLU()\n","\n","    def forward(self,secret_image):\n","        secret_cA, [secret_cD] = self.xfm(secret_image)\n","        secret_A = self.relu(self.bn1(self.conv1(secret_cA)))\n","        secret_cH = self.relu(self.bn1(self.conv1(secret_cD[:,:,0,:,:])))\n","        secret_cV = self.relu(self.bn1(self.conv1(secret_cD[:,:,1,:,:])))\n","        secret_cD = self.relu(self.bn1(self.conv1(secret_cD[:,:,2,:,:])))\n","\n","        secret_H = self.relu(self.bn2(self.conv2(secret_cH)))\n","        secret_V = self.relu(self.bn2(self.conv2(secret_cV)))\n","        secret_D = self.relu(self.bn2(self.conv2(secret_cD)))\n","\n","        secret_CD = torch.cat([secret_H,secret_V,secret_D],dim=1)\n","\n","        return secret_A, secret_CD\n","\n","class HidingNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=(4,4),stride=2,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn12 = nn.BatchNorm2d(12)\n","        self.conv3 = nn.Conv2d(in_channels=18,out_channels=36,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn36 = nn.BatchNorm2d(36)\n","        self.conv4 = nn.Conv2d(in_channels=72,out_channels=144,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn144 = nn.BatchNorm2d(144)\n","        self.conv5 = nn.Conv2d(in_channels=144,out_channels=288,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn288 = nn.BatchNorm2d(288)\n","        self.conv6 = nn.Conv2d(in_channels=288,out_channels=576,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn576 = nn.BatchNorm2d(576)\n","        self.conv7 = nn.Conv2d(in_channels=576,out_channels=1152,kernel_size=(4,4),stride=2,padding=1)\n","        \n","        self.deconv7 = nn.ConvTranspose2d(in_channels=1152,out_channels=576,kernel_size=(4,4),stride=2,padding=1)\n","        self.deconv6 = nn.ConvTranspose2d(in_channels=1152,out_channels=288,kernel_size=(4,4),stride=2,padding=1)\n","        self.deconv5 = nn.ConvTranspose2d(in_channels=576,out_channels=144,kernel_size=(4,4),stride=2,padding=1)\n","        self.deconv4 = nn.ConvTranspose2d(in_channels=288,out_channels=72,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn72 = nn.BatchNorm2d(72)\n","        self.deconv3 = nn.ConvTranspose2d(in_channels=108,out_channels=54,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn54 = nn.BatchNorm2d(54)\n","        self.deconv2 = nn.ConvTranspose2d(in_channels=66,out_channels=33,kernel_size=(4,4),stride=2,padding=1)\n","        self.bn33 = nn.BatchNorm2d(33)\n","        self.deconv1 = nn.ConvTranspose2d(in_channels=39,out_channels=3,kernel_size=(4,4),stride=2,padding=1)\n","\n","        # Define activation functions\n","        self.relu = nn.ReLU()\n","        self.lrelu = nn.LeakyReLU(0.2)\n","        self.sigmoid = nn.Sigmoid()        \n","\n","    def forward(self,secret_A, secret_CD,cover_image):\n","        output_1 = self.relu(self.conv1(cover_image))\n","        output_2 = self.relu(self.bn12(self.conv2(output_1)))\n","        concat_output_2 = torch.cat([secret_A,output_2],dim=1)        \n","        output_3 = self.relu(self.bn36(self.conv3(concat_output_2)))\n","        concat_output_3 = torch.cat([secret_CD,output_3],dim=1) \n","        output_4 = self.relu(self.bn144(self.conv4(concat_output_3)))\n","        output_5 = self.relu(self.bn288(self.conv5(output_4)))\n","        output_6 = self.relu(self.bn576(self.conv6(output_5)))\n","        output_7 = self.relu(self.conv7(output_6))\n","\n","        hidden_7 = self.lrelu(self.bn576(self.deconv7(output_7)))\n","        concat_hidden_6 = torch.cat([output_6,hidden_7],dim=1) \n","        hidden_6 = self.lrelu(self.bn288(self.deconv6(concat_hidden_6)))\n","        concat_hidden_5 = torch.cat([output_5,hidden_6],dim=1) \n","        hidden_5 = self.lrelu(self.bn144(self.deconv5(concat_hidden_5)))\n","        concat_hidden_4 = torch.cat([output_4,hidden_5],dim=1)\n","        hidden_4 = self.lrelu(self.bn72(self.deconv4(concat_hidden_4)))\n","        concat_hidden_3 = torch.cat([output_3,hidden_4],dim=1) \n","        hidden_3 = self.lrelu(self.bn54(self.deconv3(concat_hidden_3)))\n","        concat_hidden_2 = torch.cat([output_2,hidden_3],dim=1) \n","        hidden_2 = self.lrelu(self.bn33(self.deconv2(concat_hidden_2)))\n","        concat_hidden_1 = torch.cat([output_1,hidden_2],dim=1) \n","        hidden_image = self.sigmoid(self.deconv1(concat_hidden_1))\n","      \n","        return hidden_image"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"U3Oh5jAVRKXg","executionInfo":{"status":"ok","timestamp":1677756453989,"user_tz":-345,"elapsed":7,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self,prep_network,hiding_network):\n","        super().__init__()\n","        self.prep_network = prep_network\n","        self.hiding_network = hiding_network\n","    \n","    def forward(self,cover_image,secret_image):\n","        secret_A, secret_CD = self.prep_network(secret_image)\n","        \n","        hidden_image = self.hiding_network(secret_A, secret_CD,cover_image)\n","#         hidden_image = (0.01**0.5)*torch.randn(hidden_image.size(),device=device)\n","        return hidden_image"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"o8pOZbBYRxuX","executionInfo":{"status":"ok","timestamp":1677756453989,"user_tz":-345,"elapsed":6,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["# class RevealNetwork(nn.Module):\n","#     def __init__(self,ifm):\n","#         super().__init__()\n","#         self.ifm = ifm\n","#         self.conv1 = nn.Conv2d(in_channels=3,out_channels=64,kernel_size=(5,5),stride=2,padding=2)\n","#         self.bn64 = nn.BatchNorm2d(64)\n","#         self.conv2 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=(5,5),stride=2,padding=2)\n","#         self.bn128 = nn.BatchNorm2d(128)\n","#         self.conv3 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(5,5),stride=2,padding=2)\n","#         self.bn256 = nn.BatchNorm2d(256)\n","#         self.deconv1 = nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=(5,5),stride=2,padding=2)\n","#         self.deconv2 = nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=(5,5),stride=2,padding=2)\n","\n","#         self.deconvC1 = nn.ConvTranspose2d(in_channels=64,out_channels=9,kernel_size=(3,3),stride=1,padding=1)\n","#         self.bn9 = nn.BatchNorm2d(9)\n","#         self.deconvC2 = nn.ConvTranspose2d(in_channels=9,out_channels=3,kernel_size=(3,3),stride=1,padding=1)   \n","\n","#         # Define activation functions\n","#         self.relu = nn.ReLU()\n","#         self.lrelu = nn.LeakyReLU(0.2)\n","\n","#     def forward(self,hidden_image):\n","        \n","#         output_1 = self.relu(self.bn64(self.conv1(hidden_image)))\n","#         output_2 = self.relu(self.bn128(self.conv2(output_1)))\n","#         output_3 = self.relu(self.bn256(self.conv3(output_2)))\n","        \n","#         output_4 = self.lrelu(self.bn128(self.deconv1(output_3)))\n","#         output_5 = self.lrelu(self.bn64(self.deconv2(output_4)))\n","\n","#         output_A = self.lrelu(self.bn9(self.deconvC1(output_5)))\n","#         revealed_A = self.lrelu(self.deconvC2(output_A))\n","\n","#         output_H = self.lrelu(self.bn9(self.deconvC1(output_5)))\n","#         revealed_H = self.lrelu(self.deconvC2(output_H))\n","\n","#         output_V = self.lrelu(self.bn9(self.deconvC1(output_5)))\n","#         revealed_V = self.lrelu(self.deconvC2(output_V))\n","\n","#         output_D = self.lrelu(self.bn9(self.deconvC1(output_5)))\n","#         revealed_D = self.lrelu(self.deconvC2(output_D))\n","\n","#         revealed_C = torch.stack([revealed_H,revealed_V,revealed_D], dim=2)\n","#         revealed_image = self.ifm((revealed_A,[revealed_C]))\n","#         # if coeff:\n","#         #     return (revealed_A,[revealed_C])\n","#         # else:\n","#         return revealed_image"]},{"cell_type":"code","source":["class RevealNetwork(nn.Module):\n","    def __init__(self,ifm):\n","        super().__init__()\n","        self.ifm = ifm\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=39,kernel_size=(5,5),stride=2,padding=2)\n","        self.bn39 = nn.BatchNorm2d(39)\n","        self.conv2 = nn.Conv2d(in_channels=39,out_channels=66,kernel_size=(5,5),stride=2,padding=2)\n","        self.bn66 = nn.BatchNorm2d(66)\n","        self.deconv0 = nn.ConvTranspose2d(in_channels=66,out_channels=18,kernel_size=(5,5),stride=1,padding=2)\n","        self.bn18 = nn.BatchNorm2d(18)\n","        self.conv3 = nn.Conv2d(in_channels=66,out_channels=108,kernel_size=(5,5),stride=2,padding=2)\n","        self.bn108 = nn.BatchNorm2d(108)\n","\n","        self.deconv1 = nn.ConvTranspose2d(in_channels=108,out_channels=72,kernel_size=(5,5),stride=1,padding=2)\n","        self.bn72 = nn.BatchNorm2d(72)\n","        self.deconv2 = nn.ConvTranspose2d(in_channels=72,out_channels=36,kernel_size=(5,5),stride=1,padding=2)\n","        self.bn36 = nn.BatchNorm2d(36)\n","\n","        self.deconv3 = nn.ConvTranspose2d(in_channels=36,out_channels=12,kernel_size=(5,5),stride=1,padding=2)\n","        self.bn12 = nn.BatchNorm2d(12)\n","        self.deconv4 = nn.ConvTranspose2d(in_channels=18,out_channels=6,kernel_size=(5,5),stride=1,padding=2)\n","        self.deconv5 = nn.ConvTranspose2d(in_channels=12,out_channels=6,kernel_size=(3,3),stride=2,padding=1)\n","        self.deconv6 = nn.ConvTranspose2d(in_channels=6,out_channels=3,kernel_size=(3,3),stride=2,padding=1)\n","\n","        # Define activation functions\n","        self.relu = nn.ReLU()\n","        self.lrelu = nn.LeakyReLU(0.2)\n","\n","    def forward(self,hidden_image):\n","        print(hidden_image.size())\n","        output_1 = self.relu(self.bn39(self.conv1(hidden_image)))\n","        print(output_1.size())\n","        output_2 = self.relu(self.bn66(self.conv2(output_1)))\n","        print(output_2.size())\n","        output_3 = self.relu(self.bn108(self.conv3(output_2)))\n","        print(output_3.size())\n","        output_21 = self.lrelu(self.bn18(self.deconv0(output_2)))\n","        print(output_21.size())\n","        output_C3 = self.lrelu(self.bn72(self.deconv1(output_3)))\n","        print(output_21.size())\n","        output_C2 = self.lrelu(self.bn36(self.deconv2(output_C3)))\n","\n","        output_A0 = self.lrelu(self.deconv4(output_21))\n","        output_A = self.lrelu(self.deconv6(output_A0))\n","\n","        output_CH1 = self.lrelu(self.bn12(self.deconv3(output_C2)))\n","        output_CH0 = self.lrelu(self.deconv5(output_CH1))\n","        output_H = self.lrelu(self.deconv6(output_CH0))\n","        output_CV1 = self.lrelu(self.bn12(self.deconv3(output_C2)))\n","        output_CV0 = self.lrelu(self.deconv5(output_CV1))\n","        output_V = self.lrelu(self.deconv6(output_CV0))\n","        output_CD1 = self.lrelu(self.bn12(self.deconv3(output_C2)))\n","        output_CD0 = self.lrelu(self.deconv5(output_CD1))\n","        output_D = self.lrelu(self.deconv6(output_CD0))\n","        output_C = torch.stack([output_H,output_V,output_D], dim=2)\n","        print(output_C.size())\n","        print(output_A.size())\n","        revealed_image = self.ifm((output_A,[output_C]))\n","        # if coeff:\n","        #     return (revealed_A,[revealed_C])\n","        # else:\n","        return revealed_image"],"metadata":{"id":"AqvWnT5xq9oo","executionInfo":{"status":"ok","timestamp":1677758967945,"user_tz":-345,"elapsed":433,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"execution_count":110,"outputs":[]},{"cell_type":"code","source":["# class PrepNetwork(nn.Module):\n","#     def __init__(self,xfm):\n","#         super().__init__()\n","#         self.xfm = xfm\n","#         self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn1 = nn.BatchNorm2d(6)\n","#         self.conv2 = nn.Conv2d(in_channels=6,out_channels=12,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn2 = nn.BatchNorm2d(12)\n","\n","#         # Define activation functions\n","#         self.relu = nn.ReLU()\n","\n","#     def forward(self,secret_image):\n","#         secret_cA, [secret_cD] = self.xfm(secret_image)\n","#         secret_A = self.relu(self.bn1(self.conv1(secret_cA)))\n","#         secret_cH = self.relu(self.bn1(self.conv1(secret_cD[:,:,0,:,:])))\n","#         secret_cV = self.relu(self.bn1(self.conv1(secret_cD[:,:,1,:,:])))\n","#         secret_cD = self.relu(self.bn1(self.conv1(secret_cD[:,:,2,:,:])))\n","\n","#         secret_H = self.relu(self.bn2(self.conv2(secret_cH)))\n","#         secret_V = self.relu(self.bn2(self.conv2(secret_cV)))\n","#         secret_D = self.relu(self.bn2(self.conv2(secret_cD)))\n","\n","#         secret_CD = torch.cat([secret_H,secret_V,secret_D],dim=1)\n","\n","#         return secret_A, secret_CD\n","\n","# class HidingNetwork(nn.Module):\n","#     def __init__(self):\n","#         super().__init__()\n","#         self.deconv1 = nn.ConvTranspose2d(out_channels=3,in_channels=6,kernel_size=(4,4),stride=2,padding=1)\n","#         self.deconv2 = nn.ConvTranspose2d(out_channels=6,in_channels=12,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn18 = nn.BatchNorm2d(18)\n","#         self.deconv3 = nn.ConvTranspose2d(out_channels=18,in_channels=36,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn72 = nn.BatchNorm2d(72)\n","#         self.deconv4 = nn.ConvTranspose2d(out_channels=72,in_channels=144,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn144 = nn.BatchNorm2d(144)\n","#         self.deconv5 = nn.ConvTranspose2d(out_channels=144,in_channels=288,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn288 = nn.BatchNorm2d(288)\n","#         self.deconv6 = nn.ConvTranspose2d(out_channels=288,in_channels=576,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn576 = nn.BatchNorm2d(576)\n","#         self.deconv7 = nn.ConvTranspose2d(out_channels=576,in_channels=1152,kernel_size=(4,4),stride=2,padding=1)\n","        \n","#         self.conv7 = nn.Conv2d(out_channels=1152,in_channels=576,kernel_size=(4,4),stride=2,padding=1)\n","#         self.conv6 = nn.Conv2d(out_channels=1152,in_channels=288,kernel_size=(4,4),stride=2,padding=1)\n","#         self.conv5 = nn.Conv2d(out_channels=576,in_channels=144,kernel_size=(4,4),stride=2,padding=1)\n","#         self.conv4 = nn.Conv2d(out_channels=288,in_channels=72,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn108 = nn.BatchNorm2d(108)\n","#         self.conv3 = nn.Conv2d(out_channels=108,in_channels=54,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn66 = nn.BatchNorm2d(66)\n","#         self.conv2 = nn.Conv2d(out_channels=66,in_channels=33,kernel_size=(4,4),stride=2,padding=1)\n","#         self.bn39 = nn.BatchNorm2d(39)\n","#         self.conv1 = nn.Conv2d(out_channels=39,in_channels=3,kernel_size=(4,4),stride=2,padding=1)\n","\n","#         # Define activation functions\n","#         self.relu = nn.ReLU()\n","#         self.lrelu = nn.LeakyReLU(0.2)\n","#         self.sigmoid = nn.Sigmoid()        \n","\n","#     def forward(self,secret_A, secret_CD,cover_image):\n","#         output_1 = self.relu(self.conv1(cover_image)) #39\n","#         output_12 = self.relu(self.deconv1(output_1)) #33\n","#         # output11, output12 = torch.split(output_1, [6, 33], dim=1) \n","#         output_2 = self.relu(self.bn66(self.conv2(output12)))\n","#         output_2 = self.relu(self.bn66(self.deconv2(output12)))\n","#         output21, output22 = torch.split(output_2, [12, 54], dim=1) \n","               \n","#         output_3 = self.relu(self.bn108(self.conv3(output22)))\n","#         output31, output32 = torch.split(output_3, [36, 72], dim=1)\n","#         output_4 = self.relu(self.bn288(self.conv4(output32)))\n","#         output41, output42 = torch.split(output_4, [144, 144], dim=1)\n","\n","#         secret_2 = self.lrelu(self.bn72(self.deconv7(output41)))\n","#         secret21, secret22 = torch.split(secret_2, [36, 36], dim=1) \n","#         secretH2, secretV2, secretD2 = torch.split(secret21, [12, 12, 12], dim=1) \n","#         secret_1 = self.lrelu(self.bn18(self.deconv6(secret22)))\n","#         secret11, secret12 = torch.split(secret_2, [6, 12], dim=1) \n","#         secret_A1 = self.lrelu(self.bn3(self.deconv5(secret11)))\n","#         secret_H1 = self.lrelu(self.bn144(self.deconv5(secretH2)))\n","#         secret_V1 = self.lrelu(self.bn144(self.deconv5(secretV2)))\n","#         secret_D1 = self.lrelu(self.bn144(self.deconv5(secretD2)))\n","\n","\n","#         secret_A = self.lrelu(self.bn72(self.deconv4(secret_A1)))\n","#         secret_H = self.lrelu(self.bn72(self.deconv4(secret_H1)))\n","#         secret_V = self.lrelu(self.bn72(self.deconv4(secret_V1)))\n","#         secret_D = self.lrelu(self.bn72(self.deconv4(secret_D1)))\n","\n","#         secret_C = torch.stack([secret_H,secret_V,secret_D], dim=2)\n","#         secret_image = self.ifm((secret_A,[secret_C]))\n","#         # if coeff:\n","#         #     return (secret_A,[secret_C])\n","#         # else:\n","#         return secret_image"],"metadata":{"id":"G0-1bcTNTiwm","executionInfo":{"status":"ok","timestamp":1677758969669,"user_tz":-345,"elapsed":741,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"execution_count":111,"outputs":[]},{"cell_type":"code","execution_count":112,"metadata":{"id":"RZk4rMWrSPfG","executionInfo":{"status":"ok","timestamp":1677758969670,"user_tz":-345,"elapsed":22,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self,reveal_network):\n","        super().__init__()\n","        self.reveal_network = reveal_network\n","    \n","    def forward(self,hidden_image):     \n","        return self.reveal_network(hidden_image)"]},{"cell_type":"code","execution_count":113,"metadata":{"id":"Hstt-fC5Sa1L","executionInfo":{"status":"ok","timestamp":1677758969670,"user_tz":-345,"elapsed":21,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","class SteganoModel(nn.Module):\n","    def __init__(self,encoder,decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","    \n","    def forward(self,cover_image,secret_image,hidden_image,mode):\n","        if mode == 'full':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = True\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            \n","            hidden_image = self.encoder(cover_image,secret_image)\n","            reveal_image = self.decoder(hidden_image)\n","            return hidden_image,reveal_image\n","        elif mode == 'encoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","\n","            return self.encoder(cover_image,secret_image)\n","        elif mode == 'decoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = True\n","            return self.decoder(hidden_image)"]},{"cell_type":"code","execution_count":114,"metadata":{"id":"bDeY53u2Ei9V","executionInfo":{"status":"ok","timestamp":1677758969671,"user_tz":-345,"elapsed":22,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","# filename = os.path.join(\"/content/drive/MyDrive/Colab_Notebooks/Steganography/Completed_model2.joblib\")\n","# # loaded_model = joblib.load(filename)\n","# joblib.dump(model, filename)"]},{"cell_type":"code","execution_count":115,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1677758969671,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"},"user_tz":-345},"id":"I1C7fuPOS4yA","outputId":"94cc1f71-c424-495e-ebf4-6cae249aa0de"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SteganoModel(\n","  (encoder): Encoder(\n","    (prep_network): PrepNetwork(\n","      (xfm): DWTForward()\n","      (conv1): Conv2d(3, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(6, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU()\n","    )\n","    (hiding_network): HidingNetwork(\n","      (conv1): Conv2d(3, 6, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (conv2): Conv2d(6, 12, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn12): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(18, 36, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn36): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv4): Conv2d(72, 144, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn144): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv5): Conv2d(144, 288, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn288): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv6): Conv2d(288, 576, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn576): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv7): Conv2d(576, 1152, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (deconv7): ConvTranspose2d(1152, 576, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (deconv6): ConvTranspose2d(1152, 288, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (deconv5): ConvTranspose2d(576, 144, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (deconv4): ConvTranspose2d(288, 72, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn72): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv3): ConvTranspose2d(108, 54, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn54): BatchNorm2d(54, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv2): ConvTranspose2d(66, 33, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (bn33): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv1): ConvTranspose2d(39, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","      (relu): ReLU()\n","      (lrelu): LeakyReLU(negative_slope=0.2)\n","      (sigmoid): Sigmoid()\n","    )\n","  )\n","  (decoder): Decoder(\n","    (reveal_network): RevealNetwork(\n","      (ifm): DWTInverse()\n","      (conv1): Conv2d(3, 39, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","      (bn39): BatchNorm2d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv2): Conv2d(39, 66, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","      (bn66): BatchNorm2d(66, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv0): ConvTranspose2d(66, 18, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (bn18): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (conv3): Conv2d(66, 108, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n","      (bn108): BatchNorm2d(108, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv1): ConvTranspose2d(108, 72, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (bn72): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv2): ConvTranspose2d(72, 36, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (bn36): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv3): ConvTranspose2d(36, 12, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (bn12): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (deconv4): ConvTranspose2d(18, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (deconv5): ConvTranspose2d(12, 6, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (deconv6): ConvTranspose2d(6, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n","      (relu): ReLU()\n","      (lrelu): LeakyReLU(negative_slope=0.2)\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":115}],"source":["xfm = DWTForward(J=1, mode='zero', wave='db1').cuda()  # Accepts all wave types available to PyWavelets\n","ifm = DWTInverse(mode='zero', wave='db1').cuda()\n","prep_net = PrepNetwork(xfm)\n","hiding_network = HidingNetwork()\n","encoder = Encoder(prep_net,hiding_network)\n","reveal_net = RevealNetwork(ifm)\n","decoder = Decoder(reveal_net)\n","model = SteganoModel(encoder,decoder)\n","model.to(device)"]},{"cell_type":"code","execution_count":116,"metadata":{"id":"zvFzF3TJTI5Y","executionInfo":{"status":"ok","timestamp":1677758969672,"user_tz":-345,"elapsed":15,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["class SteganoLoss(nn.Module):\n","    def __init__(self,cover_weight,secret_weight):\n","        super().__init__()\n","        self.cover_weight = cover_weight\n","        self.secret_weight = secret_weight\n","        # self.xfm = xfm\n","    def forward(self,predicted_cover_image,cover_image,\n","               predicted_secret_image,secret_image):\n","        # (secretcA,[secretcD]) = self.xfm(secret_image)\n","        # (psecretcA,[psecretcD]) = predicted_secret_image\n","        cover_loss = self.cover_weight*(F.mse_loss(predicted_cover_image,cover_image))\n","        secret_loss = self.secret_weight*(F.mse_loss(predicted_secret_image,secret_image)) \n","        return cover_loss + secret_loss\n","\n","class DecoderLoss(nn.Module):\n","    def __init__(self,decoder_loss_weight):\n","        super().__init__()\n","        self.decoder_loss_weight = decoder_loss_weight\n","        # self.xfm = xfm\n","    \n","    def forward(self,reveal_output,secret_image):\n","        # (secretcA,[secretcD]) = self.xfm(secret_image)\n","        # (psecretcA,[psecretcD]) = reveal_output\n","        return self.decoder_loss_weight*(F.mse_loss(reveal_output,secret_image)) "]},{"cell_type":"code","execution_count":117,"metadata":{"id":"b9v52sPcTzPI","executionInfo":{"status":"ok","timestamp":1677758969672,"user_tz":-345,"elapsed":15,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","# # training_csv_path = os.path.join(dataset_path,train_dataset.csv)\n","# # test_csv_path = os.path.join(dataset_path,test_csv)\n","\n","training_dataset = SteganoDataset('/content/drive/MyDrive/Colab Notebooks/Steganography/MyData.csv',imagetransformation['train_transforms'],'train','complete')\n","# test_dataset = SteganoDataset(training_csv_path,imagetransformation['train_transforms'],'Train','complete')\n"]},{"cell_type":"code","execution_count":118,"metadata":{"id":"qfWfE_rdcywx","executionInfo":{"status":"ok","timestamp":1677758969672,"user_tz":-345,"elapsed":15,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","# test_dataset = SteganoDataset(dataframe,imagetransformation['test_transforms'],'Valid')\n","\n","\n","train_data_loader = torch.utils.data.DataLoader(training_dataset, \n","                                                batch_size = TRAIN_BATCH_SIZE, \n","                                                shuffle=True,\n","                                               drop_last = True,\n","                                               num_workers = 0\n","                                               )\n","# valid_data_loader = torch.utils.data.DataLoader(valid_dataset, \n","#                                                 batch_size = VALID_BATCH_SIZE, \n","#                                                 shuffle=True,\n","#                                                 drop_last = True,\n","#                                                 num_workers = 0\n","#                                                )\n","                                               \n","# test_data_loader = torch.utils.data.DataLoader(test_dataset, \n","#                                                 batch_size = VALID_BATCH_SIZE, \n","#                                                 shuffle=True,\n","#                                                 drop_last = True,\n","#                                                 num_workers = 0\n","#                                                )\n","\n"]},{"cell_type":"code","execution_count":119,"metadata":{"id":"_hvQLeCfjyug","executionInfo":{"status":"ok","timestamp":1677758969673,"user_tz":-345,"elapsed":15,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","full_model_criterion = SteganoLoss(SECRET_LOSS_WEIGHT,COVER_LOSS_WEIGHT)\n","\n","full_model_optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)\n","\n","decoder_criterion = DecoderLoss(DECODER_LOSS_WEIGHT)\n","training_full_model_loss_list = []\n","decoder_loss_list = []\n"]},{"cell_type":"code","execution_count":120,"metadata":{"id":"sZVmw3xWUFum","executionInfo":{"status":"ok","timestamp":1677758969673,"user_tz":-345,"elapsed":15,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","def train(model,epochs,decoder_criterion,full_model_optimizer,full_model_criterion,learning_rate,training_iterator):\n","    print_every=1\n","    counter=1\n","\n","    for epoch in range(epochs):\n","        for index,training_dict in enumerate(training_iterator):\n","            cover_image = training_dict['cover_image']\n","            cover_image = cover_image.to(device)\n","            \n","            secret_image = training_dict['secret_image']\n","            secret_image = secret_image.to(device)\n","            counter=counter+1\n","\n","\n","            full_model_optimizer.zero_grad()\n","\n","            encoder_output = model(cover_image,secret_image,secret_image,'encoder')\n","\n","            hidden_image,reveal_image = model(cover_image,secret_image,secret_image,'full')\n","            \n","            full_model_loss = full_model_criterion(hidden_image,cover_image, reveal_image,secret_image)\n","            \n","            full_model_loss.backward()\n","            full_model_optimizer.step()\n","            \n","            full_model_optimizer.zero_grad()\n","            reveal_output = model(cover_image,secret_image,encoder_output,'decoder')\n","                                                                 \n","            decoder_loss = decoder_criterion(reveal_output,secret_image)\n","\n","            decoder_loss.backward()\n","            full_model_optimizer.step()\n","            if counter % 50 == 0:\n","              print(full_model_loss)\n","            \n","\n","        training_full_model_loss_list.append(full_model_loss)\n","        decoder_loss_list.append(decoder_loss)\n","        if epoch % print_every == 0:\n","            print(\"Training full model loss at {} epochs is: {}\".format(epoch, full_model_loss))\n","            print(\"Training decoder loss at {} epochs is: {}\".format(epoch, decoder_loss))\n","\n","    return model, training_full_model_loss_list,decoder_loss_list\n"]},{"cell_type":"markdown","metadata":{"id":"rE94MW8u5_2n"},"source":["Training full model loss at 0 epochs is: 0.14862200617790222\n","Training decoder loss at 0 epochs is: 0.056159209460020065\n","Training full model loss at 50 epochs is: 0.010316253639757633\n","Training decoder loss at 50 epochs is: 0.006905762478709221\n","Training full model loss at 100 epochs is: 0.005915718153119087\n","Training decoder loss at 100 epochs is: 0.004135390743613243\n","Training full model loss at 150 epochs is: 0.00597141869366169\n","Training decoder loss at 150 epochs is: 0.003256219904869795\n","Training full model loss at 200 epochs is: 0.004562869668006897\n","Training decoder loss at 200 epochs is: 0.0032390698324888945\n","Training full model loss at 250 epochs is: 0.004033954814076424\n","Training decoder loss at 250 epochs is: 0.00324784847907722\n","Training full model loss at 300 epochs is: 0.0028372027445584536\n","Training decoder loss at 300 epochs is: 0.002142705488950014\n","Training full model loss at 350 epochs is: 0.003511040238663554\n","Training decoder loss at 350 epochs is: 0.0028315880335867405\n","Training full model loss at 400 epochs is: 0.006889783777296543\n","Training decoder loss at 400 epochs is: 0.006818610243499279\n","Training full model loss at 450 epochs is: 0.0030810432508587837\n","Training decoder loss at 450 epochs is: 0.0027422530110925436\n","Training full model loss at 500 epochs is: 0.0026186055038124323\n","Training decoder loss at 500 epochs is: 0.00222468632273376\n","Training full model loss at 550 epochs is: 0.0022935508750379086\n","Training decoder loss at 550 epochs is: 0.0016986110713332891\n","Training full model loss at 600 epochs is: 0.0017199815483763814\n","Training decoder loss at 600 epochs is: 0.0012137810699641705\n","Training full model loss at 650 epochs is: 0.002981864381581545\n","Training decoder loss at 650 epochs is: 0.002139737131074071\n","Training full model loss at 700 epochs is: 0.00157183688133955\n","Training decoder loss at 700 epochs is: 0.0011825517285615206\n","Training full model loss at 750 epochs is: 0.001144192647188902\n","Training decoder loss at 750 epochs is: 0.0006921886233612895\n","Training full model loss at 800 epochs is: 0.0016071755671873689\n","Training decoder loss at 800 epochs is: 0.0011148437624797225\n","Training full model loss at 850 epochs is: 0.0016389719676226377\n","Training decoder loss at 850 epochs is: 0.0010738647542893887\n","Training full model loss at 900 epochs is: 0.0011910195462405682\n","Training decoder loss at 900 epochs is: 0.0007727841730229557\n","Training full model loss at 950 epochs is: 0.0011191064259037375\n","Training decoder loss at 950 epochs is: 0.0007212755153886974"]},{"cell_type":"code","source":["import os\n","import random\n","import shutil\n","import pandas as pd\n","\n","# Set the path to the destination folders\n","secret_path = '/content/drive/MyDrive/Colab Notebooks/Dataset256/secret'\n","cover_path = '/content/drive/MyDrive/Colab Notebooks/Dataset256/cover'\n","\n","# Get a list of all the images in the folder\n","secret_img_list = os.listdir(secret_path)\n","cover_img_list = os.listdir(cover_path)\n","print(len(secret_img_list))\n","print(len(cover_img_list))\n","# # Create a dataframe from the cover and secret image lists\n","# dataset = pd.DataFrame(columns=['cover_image', 'secret_image'])\n","# for i in range(len(cover_img_list)):\n","#     dataset = dataset.append({\n","#         'cover_image': cover_img_list[i],\n","#         'secret_image': secret_img_list[i]\n","#     }, ignore_index=True)\n","\n","# # Save the dataframe as a CSV file\n","# dataset.to_csv('Dataset_x256.csv', index=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5jjN7TcTvfC8","executionInfo":{"status":"ok","timestamp":1677758969673,"user_tz":-345,"elapsed":14,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}},"outputId":"2f5d516f-b06f-4e75-cc5c-0d150c66c4da"},"execution_count":121,"outputs":[{"output_type":"stream","name":"stdout","text":["1000\n","991\n"]}]},{"cell_type":"code","execution_count":122,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484},"id":"3Zo_lYACU0o9","outputId":"f13e955f-65b1-4a7d-b3fa-0d22e1d3ce55","executionInfo":{"status":"error","timestamp":1677758973518,"user_tz":-345,"elapsed":3853,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","2\n","3\n","4\n","5\n","6\n","7\n","torch.Size([16, 3, 3, 125, 125])\n","torch.Size([16, 3, 127, 127])\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-122-0f434b4de9d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_full_model_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_loss_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_model_criterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-120-dc7bf4b8602e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epochs, decoder_criterion, full_model_optimizer, full_model_criterion, learning_rate, training_iterator)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mencoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecret_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecret_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'encoder'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mhidden_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreveal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecret_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecret_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'full'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mfull_model_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_model_criterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcover_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreveal_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecret_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-113-0073e2fb7031>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, cover_image, secret_image, hidden_image, mode)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mhidden_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcover_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msecret_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mreveal_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreveal_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'encoder'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-112-d2c21d029ae8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_image)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreveal_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-110-deaebe5d143c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_image)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mrevealed_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mifm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput_C\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;31m# if coeff:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_wavelets/dwt/transform2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, coeffs)\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                 \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             ll = lowlevel.SFB2D.apply(\n\u001b[0m\u001b[1;32m    147\u001b[0m                 ll, h, self.g0_col, self.g1_col, self.g0_row, self.g1_row, mode)\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_wavelets/dwt/lowlevel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, low, highs, g0_row, g1_row, g0_col, g1_col, mode)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mlh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhighs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mlo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfb1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg0_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0mhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfb1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg0_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msfb1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg0_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pytorch_wavelets/dwt/lowlevel.py\u001b[0m in \u001b[0;36msfb1d\u001b[0;34m(lo, hi, g0, g1, mode, dim)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'periodic'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_transpose2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m                 \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_transpose2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (126) must match the size of tensor b (125) at non-singleton dimension 3"]}],"source":["model, training_full_model_loss_list, decoder_loss_list = train(model, EPOCHS,decoder_criterion, full_model_optimizer, full_model_criterion, LEARNING_RATE, train_data_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wi8qChAmE_p","executionInfo":{"status":"aborted","timestamp":1677758973520,"user_tz":-345,"elapsed":45,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["filename = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Steganography/unetmodel.pkl\")\n","# loaded_model = joblib.load(filename)\n","torch.save(model,filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBkKVTiRm3Vx","executionInfo":{"status":"aborted","timestamp":1677758973520,"user_tz":-345,"elapsed":44,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["# model = torch.load('/content/drive/MyDrive/Colab Notebooks/Steganography/stegomodel_latest.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xU1b58w-YKxo","executionInfo":{"status":"aborted","timestamp":1677758973521,"user_tz":-345,"elapsed":44,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","def predict(model,iterator,mode):\n","\n","    predict_dict = next(iter(iterator))\n","    cover_image = predict_dict['cover_image']\n","    # print(cover_image)\n","    cover_image = cover_image.to(device)\n","    secret_image_1 = predict_dict['secret_image']\n","    secret_image_1 = secret_image_1.to(device)\n","\n","    model.eval()\n","\n"," \n","    if mode =='decoder':\n","      \n","      reveal_image_1= model(cover_image,cover_image,cover_image,mode)\n","      \n","      # dot_graph = torchviz.make_dot(model(cover_image,cover_image,cover_image,mode))\n","      # dot_graph.render(\"decoder.dot\")\n","    elif mode =='encoder':\n","      hidden_image= model(cover_image,secret_image_1,secret_image_1,mode)\n","      # dot_graph = torchviz.make_dot(model(cover_image,secret_image_1,secret_image_1,mode))\n","      # dot_graph.render(\"encoder.dot\")\n","    elif mode == \"full\":\n","      hidden_image,reveal_image_1= model(cover_image,secret_image_1,secret_image_1,mode)\n","      # dot_graph = torchviz.make_dot(model(cover_image,secret_image_1,secret_image_1,mode))\n","      # dot_graph.render(\"full.dot\")\n","      cover_image = cover_image * 255\n","      cover_image = cover_image.to(torch.device('cpu'))\n","      cover_image = cover_image.detach().to(torch.long)\n","      secret_image_1 = secret_image_1 * 255\n","      secret_image_1 = secret_image_1.to(torch.device('cpu'))\n","      secret_image_1 = secret_image_1.detach().to(torch.long)\n","    if mode =='encoder' or mode == 'full':\n","      hidden_image[hidden_image>1] = 1\n","      hidden_image = hidden_image * 255\n","      hidden_image = hidden_image.to(torch.device('cpu'))\n","      hidden_image = hidden_image.detach().to(torch.long)\n","      h = hidden_image[0].permute(1,2,0).numpy()\n","      im = Image.fromarray(h.astype(np.uint8))\n","      im.save(\"/content/drive/MyDrive/Colab Notebooks/stego_img.png\")\n","      if mode == 'encoder': return h\n","    if mode =='decoder' or mode == 'full':\n","      reveal_image_1[reveal_image_1>1] = 1\n","      reveal_image_1 = reveal_image_1 * 255\n","      reveal_image_1 = reveal_image_1.to(torch.device('cpu'))\n","      reveal_image_1 = reveal_image_1.detach().to(torch.long)\n","      r = reveal_image_1[0].permute(1,2,0).numpy()\n","      im = Image.fromarray(r.astype(np.uint8))\n","      im.save(\"/content/drive/MyDrive/Colab Notebooks/revealed.png\")\n","      if mode == 'encoder': return r\n","    return {\n","        'cover_image_grid':cover_image[0].permute(1,2,0).numpy(),\n","        'secret_image_1_grid':secret_image_1[0].permute(1,2,0).numpy(),\n","        'hidden_image_grid':h,\n","        'reveal_image_1_grid':r,\n","    }\n","grids = predict(model,train_data_loader,'full')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waVaTJ8_jMnj","executionInfo":{"status":"aborted","timestamp":1677758973521,"user_tz":-345,"elapsed":44,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["import torch\n","import math, time, sys\n","from PIL import Image\n","\n","class Arnold:\n","\n","    def __init__(self, a:int, b:int, rounds:int):\n","        # Parameters\n","        self.a = a\n","        self.b = b\n","        self.rounds = rounds\n","\n","    def mapping(self, s:torch.Size):\n","        x, y = torch.meshgrid(torch.arange(s[0]), torch.arange(s[1]))\n","        xmap = (self.a*self.b*x + x + self.a*y) % s[0]\n","        ymap = (self.b*x + y) % s[1]\n","        return xmap, ymap\n","\n","    def inverseMapping(self, s:torch.Size):\n","        x, y = torch.meshgrid(torch.arange(s[0]), torch.arange(s[1]))\n","        xmap = (x - self.a*y) % s[0]\n","        ymap = (-self.b*x + self.a*self.b*y + y) % s[1]\n","        return xmap, ymap\n","\n","    def applyTransformTo(self, image:torch.Tensor):\n","        xm, ym = self.mapping(image.shape[-2:])\n","        img = image\n","        for r in range(self.rounds):\n","            img = img[..., xm, ym]\n","        return img\n","\n","    def applyInverseTransformTo(self, image:torch.Tensor):\n","        xm, ym = self.inverseMapping(image.shape[-2:])\n","        img = image\n","        for r in range(self.rounds):\n","            img = img[..., xm, ym]\n","        return img\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0B_YuKsGLr91","executionInfo":{"status":"aborted","timestamp":1677758973522,"user_tz":-345,"elapsed":43,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["# grids['cover_image_grid'] = arnold.applyInverseTransformTo(grids['cover_image_grid'])\n","# grids['hidden_image_grid'] = arnold.applyInverseTransformTo(grids['hidden_image_grid'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0ioALQYWSwe","executionInfo":{"status":"aborted","timestamp":1677758973523,"user_tz":-345,"elapsed":43,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["def plot(grids):\n","    plt.figure(figsize=(15,8))\n","    \n","    plt.subplot(241)\n","    plt.title('Cover Image')\n","    plt.imshow(grids['cover_image_grid'])\n","\n","    plt.subplot(242)\n","    plt.title('Secret Image')\n","    plt.imshow(grids['secret_image_1_grid'])\n","\n","    plt.subplot(245)\n","    plt.title('Hidden Image')\n","    plt.imshow(grids['hidden_image_grid'])\n","    \n","    plt.subplot(246)\n","    plt.title('Reveal Image')\n","    plt.imshow(grids['reveal_image_1_grid'])\n","\n","    plt.savefig('/content/drive/MyDrive/Colab Notebooks/Plot.png')\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SIZqG9NWnOe","executionInfo":{"status":"aborted","timestamp":1677758973523,"user_tz":-345,"elapsed":43,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["plot(grids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GuQOu96oQAed","executionInfo":{"status":"aborted","timestamp":1677758973524,"user_tz":-345,"elapsed":44,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["import pickle\n","import torchviz\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwxM31L4QCoW","executionInfo":{"status":"aborted","timestamp":1677758973524,"user_tz":-345,"elapsed":44,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["!pip install torchviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbm-ZBmXV3aw","executionInfo":{"status":"aborted","timestamp":1677758973525,"user_tz":-345,"elapsed":44,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["!apt-get install -y graphviz\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgLwNLzAWAbe","executionInfo":{"status":"aborted","timestamp":1677758973526,"user_tz":-345,"elapsed":45,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["!dot -Tpng full.dot -o full.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpNXpNaAZGOj","executionInfo":{"status":"aborted","timestamp":1677758973527,"user_tz":-345,"elapsed":46,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["!dot -Tpng encoder.dot -o encodermodel.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ozq3kymAZegG","executionInfo":{"status":"aborted","timestamp":1677758973528,"user_tz":-345,"elapsed":45,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["!dot -Tpng decoder.dot -o decodermodel.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgOJsRxiVjjH","executionInfo":{"status":"aborted","timestamp":1677758973530,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["torchviz.render(model, \"model.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejQRClCccysX","executionInfo":{"status":"aborted","timestamp":1677758973531,"user_tz":-345,"elapsed":48,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["# def predict(cover,model=test):\n","#   mode='decoder'\n","#   cover=torchvision.transforms.Compose([torchvision.transforms.Resize((512,512)),torchvision.transforms.ToTensor(cover)])\n","#   cover = cover.to(device)\n","#   model.eval()\n","#   reveal_image_1= model(cover,cover,cover,mode)\n","#   reveal_image_1[reveal_image_1>1] = 1\n","#   reveal_image_1 = reveal_image_1 * 255\n","#   reveal_image_1 = reveal_image_1.to(torch.device('cpu'))\n","#   reveal_image_1 = reveal_image_1.detach().to(torch.long)\n","#   r = reveal_image_1[0].permute(1,2,0).numpy()\n","#   im = Image.fromarray(r.astype(np.uint8))\n","#   return im"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7FdUR-Bqe2J","executionInfo":{"status":"aborted","timestamp":1677758973531,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["from torchvision.utils import save_image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzHpnf22U2vD","executionInfo":{"status":"aborted","timestamp":1677758973532,"user_tz":-345,"elapsed":48,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["'''\n","data = next(iter(test_data_loader))\n","\n","cover_image = data['cover_image']\n","cover_image = cover_image.to(device)\n","\n","secret_image_1 = data['secret_image']\n","secret_image_1 = secret_image_1.to(device)\n","\n","model.eval()\n","    \n","hidden_image,reveal_image_1 = model(cover_image,secret_image_1,secret_image_1,'full')\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5MDSPFzuVIXM","executionInfo":{"status":"aborted","timestamp":1677758973532,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["#make_dot(hidden_image).render('hidden_image',format='png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3GlMMmYVNKx","executionInfo":{"status":"aborted","timestamp":1677758973532,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["#make_dot(reveal_image_1).render('reveal_image',format='png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"woB2-YkIVSeo","executionInfo":{"status":"aborted","timestamp":1677758973532,"user_tz":-345,"elapsed":46,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","def plot_loss(loss_list,num):\n","    plt.plot(torch.tensor(loss_list, device = 'cpu'))\n","    if(num==1):\n","      plt.title('full mode loss')\n","      plt.xlabel(\"epochs\")\n","      plt.ylabel(\"loss\")\n","      plt.savefig('/content/drive/MyDrive/Colab Notebooks/fullmodeloss11.png')\n","      plt.show()\n","    else:\n","      plt.title('decoder loss')\n","      plt.xlabel(\"epochs\")\n","      plt.ylabel(\"loss\")\n","      plt.savefig('/content/drive/MyDrive/Colab Notebooks/decoderloss11.png')\n","      plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ztDFJYfVTb5","executionInfo":{"status":"aborted","timestamp":1677758973532,"user_tz":-345,"elapsed":46,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["plot_loss(training_full_model_loss_list,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNk5S83VVWOf","executionInfo":{"status":"aborted","timestamp":1677758973533,"user_tz":-345,"elapsed":46,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["plot_loss(decoder_loss_list,2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6hg_MrhWsI6","executionInfo":{"status":"aborted","timestamp":1677758973533,"user_tz":-345,"elapsed":46,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","for i in range(5):\n","    grids = predict(test,test_data_loader,'full')\n","    plot(grids)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J0tiuDd6l9rM","executionInfo":{"status":"aborted","timestamp":1677758973533,"user_tz":-345,"elapsed":45,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["def wtransform(img):\n","  image = np.array(img)\n","  coeffs = [[],[],[]]\n","\n","  for ch in range(3):\n","    # Perform wavelet transform\n","    coeffs[ch] = pywt.swt2(image[:,:,ch], 'haar',level=1)\n","  return coeffs, image\n","def iwtransform(coeffs,image):\n","  image[:,:,0] = pywt.iswt2(coeffs[0], 'haar')\n","  image[:,:,1] = pywt.iswt2(coeffs[1], 'haar')\n","  image[:,:,2] = pywt.iswt2(coeffs[2], 'haar')\n","  return Image.fromarray(np.uint8(image))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGtxtCQxyYM9","executionInfo":{"status":"aborted","timestamp":1677758973534,"user_tz":-345,"elapsed":46,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["from matplotlib.image import imread\n","import matplotlib.pyplot as plt\n","import pywt\n","plt.rcParams['figure.figsize'] = [16, 16]\n","plt.rcParams.update({'font.size': 18})\n","\n","A = Image.open('/content/drive/MyDrive/Colab Notebooks/Steganography/NikeshC.jpg')\n","print(type(A))\n","B = np.mean(A, -1); # Convert RGB to grayscale\n","\n","n = 1\n","w = 'db1'\n","coeff = [[],[]]\n","arr = [[],[],[]]\n","coeff_slices = [[],[],[]]\n","for ch in range(3):\n","  coeffs = pywt.swt2(A[:,:,ch],wavelet=w,level=n)\n","  # data = np.zeros_like(A)\n","  # print(data.shape)\n","  # print(coeffs[0])\n","  # coeffs[1] = pywt.wavedec2(A[:,:,1],wavelet=w,level=n)\n","  # coeffs[2] = pywt.wavedec2(A[:,:,2],wavelet=w,level=n)\n","\n","  # normalize each coefficient array\n","  \n","  coeff[0] = coeffs[0][0] / np.abs(coeffs[0][0]).max()\n","  for detail_level in range(n):\n","      coeff[detail_level + 1] = [d/np.abs(d).max() for d in coeffs[0][detail_level + 1]]\n","\n","  arr[ch], coeff_slices[ch] = np.array(pywt.coeffs_to_array(coeff))\n","\n","final_img = np.dstack([arr[0]*255, arr[1]*255, arr[2]*255]).astype(np.uint8)\n","print(final_img.shape)\n","\n","# a = arr[coeff_slices[1]['dd']]\n","plt.imshow(final_img,cmap='gray',vmin=-0.25,vmax=0.75)\n","plt.savefig('/content/drive/MyDrive/Colab Notebooks/Plotwave4.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQsCDAUSljqp","executionInfo":{"status":"aborted","timestamp":1677758973535,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","r_np = imread('/content/drive/MyDrive/Colab Notebooks/Plotwave2.png')\n","g_np = imread('/content/drive/MyDrive/Colab Notebooks/Plotwave3.png')\n","b_np = imread('/content/drive/MyDrive/Colab Notebooks/Plotwave4.png')\n","\n","\n","# Add the channels to the final image\n","final_img = np.dstack([b_np[:,:,0], g_np[:,:,2], r_np[:,:,2]]).astype(np.uint8)\n","\n","print(final_img.shape)\n","plt.imshow(final_img, interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkPOtNqJ30NA","executionInfo":{"status":"aborted","timestamp":1677758973535,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["import numpy as np\n","import math, time, sys\n","from PIL import Image\n","class Arnold:\n","\n","    def __init__(self, a:int, b:int, rounds:int):\n","        # Parameters\n","        self.a = a\n","        self.b = b\n","        self.rounds = rounds\n","\n","    def mapping(self, s:np.shape):\n","        x, y = np.meshgrid(range(s[0]), range(s[0]), indexing=\"ij\")\n","        xmap = (self.a*self.b*x + x + self.a*y) % s[0]\n","        ymap = (self.b*x + y) % s[0]\n","        return xmap, ymap\n","\n","    def inverseMapping(self, s:np.shape):\n","        x, y = np.meshgrid(range(s[0]), range(s[0]), indexing=\"ij\")\n","        xmap = (x - self.a*y) % s[0]\n","        ymap = (-self.b*x + self.a*self.b*y + y) % s[0]\n","        return xmap, ymap\n","\n","    def applyTransformTo(self, image:np.ndarray):\n","        xm, ym = self.mapping(image.shape)\n","        img = image\n","        for r in range(self.rounds):\n","            img = img[xm, ym]\n","        return img\n","\n","    def applyInverseTransformTo(self, image:np.ndarray):\n","        xm, ym = self.inverseMapping(image.shape)\n","        img = image\n","        for r in range(self.rounds):\n","          img = img[xm, ym]\n","        return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hczxr-re4FaQ","executionInfo":{"status":"aborted","timestamp":1677758973536,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["\n","image_path = \"/content/drive/MyDrive/Colab Notebooks/Steganography/Nikesh.jpg\"\n","\n","# Arnold Transform Parameters\n","a = 6\n","b = 40\n","rounds = 33\n","\n","# Open the images\n","lena = np.array(Image.open(image_path))\n","\n","print(\" ~~~~  * PARAMETERS *  ~~~~ \")\n","arnold = Arnold(a, b, rounds)\n","print(\"\\ta:\\t\", a)\n","print(\"\\tb:\\t\", b)\n","print(\"\\trounds:\\t\", rounds)\n","\n","print(\"\\n ~~~~  *  RESULTS   *  ~~~~ \")\n","\n","start_time = time.time()\n","scrambled = arnold.applyTransformTo(lena)\n","exec_time = time.time() - start_time\n","print(\"Transform  execution time: %.6f \" % exec_time, \"sec\")\n","im = Image.fromarray(scrambled)\n","im.save(\"/content/drive/MyDrive/Colab Notebooks/Steganography/scrambledInvert.png\", format=\"PNG\")\n","\n","start_time = time.time()\n","reconstructed = arnold.applyInverseTransformTo(scrambled)\n","exec_time = time.time() - start_time\n","print(\"Inverse T. execution time: %.6f \" % exec_time, \"sec\")\n","im = Image.fromarray(reconstructed)\n","im.save(\"/content/drive/MyDrive/Colab Notebooks/reconstructed\", format=\"PNG\")\n"]},{"cell_type":"markdown","metadata":{"id":"R0nhU_A_2_RC"},"source":["<h1>Analysis Code</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5xzk706290W","executionInfo":{"status":"aborted","timestamp":1677758973536,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["import math\n","import numpy as np\n","import cv2\n","from matplotlib.image import imread\n","from scipy.stats import entropy\n","import matplotlib.pyplot as plt\n","\n","def psnr(img1, img2):\n","    mse = np.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    PIXEL_MAX = 255.0\n","    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n","\n","def snr(stego_image, original_image):\n","    # Calculate the noise image\n","    noise_image = stego_image - original_image\n","    # Calculate the average noise power\n","    noise_power = np.mean(noise_image ** 2)\n","    # Calculate the average signal power\n","    signal_power = np.mean(original_image ** 2)\n","    # Calculate the SNR\n","    snr = signal_power / noise_power\n","    # Convert the SNR to decibels\n","    snr_db = 10 * np.log10(snr)\n","    return snr_db\n","\n","def ssim(image1, image2):\n","    # Convert the images to grayscale\n","    image1_gray = cv2.cvtColor(cv2.convertScaleAbs(image1), cv2.COLOR_BGR2GRAY)\n","    image2_gray = cv2.cvtColor(cv2.convertScaleAbs(image2), cv2.COLOR_BGR2GRAY)\n","    # Calculate the SSIM\n","    ssim, _ = cv2.quality.QualityMSE_compute(image1_gray, image2_gray)\n","    return ssim\n","\n","def correlation_coefficient(image1, image2):\n","    # Flatten the images into 1D arrays\n","    image1_flat = image1.flatten()\n","    image2_flat = image2.flatten()\n","    # Calculate the correlation coefficient\n","    correlation = np.corrcoef(image1_flat, image2_flat)[0, 1]\n","    return correlation\n","\n","def image_entropy(image):\n","    # Flatten the image into a 1D array\n","    image_flat = image.flatten()\n","    # Calculate the entropy\n","    return entropy(image_flat)\n","\n","def pixel_frequencies(image):\n","    # Flatten the image into a 1D array\n","    image_flat = image.flatten()\n","    # Calculate the frequencies of each pixel value\n","    unique, counts = np.unique(image_flat, return_counts=True)\n","    frequencies = counts / len(image_flat)\n","    return unique, frequencies,counts\n","\n","def plot_frequencies(unique, frequencies,counts):\n","    # Plot the frequencies\n","    plt.plot(unique, counts)\n","    plt.xlim([0, 256])\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"27Cwoaon2sGP"},"source":["<h1>For Loop</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdBjAvLa22Eb","executionInfo":{"status":"aborted","timestamp":1677758973536,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["cover = Image.open(cover)\n","secret = Image.open(secret)\n","grids = predict(model,test_data_loader,'full')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9fSboe34EMg","executionInfo":{"status":"aborted","timestamp":1677758973536,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["cpath = '/content/drive/MyDrive/Colab Notebooks/Steganography/Dataset/cover'\n","spath = '/content/drive/MyDrive/Colab Notebooks/Steganography/Dataset/train'\n","listofcimg = os.listdir(cpath)\n","listofsimg = os.listdir(spath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p70UwYO63Xms","executionInfo":{"status":"aborted","timestamp":1677758973537,"user_tz":-345,"elapsed":47,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["df = pd.DataFrame(columns=[\"psnrC\", \"psnrS\", \"snrC\", \"snrS\", \"ssimC\", \"ssimS\", \"corrC\", \"corrS\", \"entC\", \"entH\", \"entS\", \"entR\"])\n","for i in range(1000):\n","  dataset = [{\n","        'cover_image':os.path.join(cpath,listofcimg[i]),\n","        'secret_image':os.path.join(spath,listofsimg[i])\n","    }]\n","  dataframe = pd.DataFrame(dataset)\n","  test_dataset = SteganoDataset(dataframe,imagetransformation['test_transforms'],'Valid')                                               \n","  test_data_loader = torch.utils.data.DataLoader(test_dataset, \n","                                                  batch_size = VALID_BATCH_SIZE, \n","                                                  shuffle=True,\n","                                                  drop_last = True,\n","                                                  num_workers = 0\n","                                                )\n","\n","  grids = predict(model,test_data_loader,'full')\n","  psnrC = psnr(grids['cover_image_grid'],grids['hidden_image_grid'])\n","  psnrS = psnr(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])\n","  snrC = snr(grids['cover_image_grid'],grids['hidden_image_grid'])\n","  snrS = snr(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])\n","  ssimC = ssim(grids['cover_image_grid'],grids['hidden_image_grid'])[0]\n","  ssimS = ssim(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])[0]\n","  corrC = correlation_coefficient(grids['cover_image_grid'],grids['hidden_image_grid'])\n","  corrS = correlation_coefficient(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])\n","  entC = image_entropy(grids['cover_image_grid'])\n","  entH = image_entropy(grids['hidden_image_grid'])\n","  entS = image_entropy(grids['secret_image_1_grid'])\n","  entR = image_entropy(grids['reveal_image_1_grid'])\n","  df = df.append({\"psnrC\": psnrC, \"psnrS\": psnrS, \"snrC\": snrC, \"snrS\": snrS, \"ssimC\": ssimC, \"ssimS\": ssimS, \"corrC\": corrC, \"corrS\": corrS, \"entC\": entC, \"entH\": entH, \"entS\": entS, \"entR\": entR}, ignore_index=True)\n","\n","df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Steganography/table.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4_GrppXTcC9","executionInfo":{"status":"aborted","timestamp":1677758973539,"user_tz":-345,"elapsed":49,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["df_norm = df.apply(lambda x: (x - x.mean()) / x.std())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4w-EDbR2P1Nd","executionInfo":{"status":"aborted","timestamp":1677758973540,"user_tz":-345,"elapsed":50,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["df.plot(y='psnrS')\n","plt.xlabel(\"Image number\")\n","plt.ylabel(\"PSNR\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaBTcnhVQYHQ","executionInfo":{"status":"aborted","timestamp":1677758973541,"user_tz":-345,"elapsed":51,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgnMEBp6Qcij","executionInfo":{"status":"aborted","timestamp":1677758973541,"user_tz":-345,"elapsed":51,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["sns.heatmap(df.corr())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqMDc2YvSERO","executionInfo":{"status":"aborted","timestamp":1677758973542,"user_tz":-345,"elapsed":52,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["df.mean(axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SdFQixvgiAp","executionInfo":{"status":"aborted","timestamp":1677758973543,"user_tz":-345,"elapsed":53,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["from skimage.metrics import structural_similarity as ssim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYKOHFwXhIDx","executionInfo":{"status":"aborted","timestamp":1677758973543,"user_tz":-345,"elapsed":52,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["ssimValue = ssim(grids['cover_image_grid'],grids['secret_image_1_grid'],win_size=11, multichannel = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRmWeeuNirtY","executionInfo":{"status":"aborted","timestamp":1677758973544,"user_tz":-345,"elapsed":53,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["ssimValue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQh2JJ0uj-hI","executionInfo":{"status":"aborted","timestamp":1677758973544,"user_tz":-345,"elapsed":53,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["from pyssim import SSIM \n","ssim = SSIM()\n","score = ssim.compute(grids['cover_image_grid'],grids['secret_image_1_grid'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oicWsTn2kkG2","executionInfo":{"status":"aborted","timestamp":1677758973545,"user_tz":-345,"elapsed":54,"user":{"displayName":"Biplov Karna","userId":"08924113999811717406"}}},"outputs":[],"source":["!pip install pyssim"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}