{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"ZRG0HrYFnBOz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676552992525,"user_tz":-345,"elapsed":4886,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"}},"outputId":"1cd36c14-2cff-470f-9144-12ea4c58f7d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# yo chai ho hai\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3or6R6we1LZV"},"outputs":[],"source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np \n","import pandas as pd\n","import torchvision\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import joblib\n","from google.colab import drive\n","import pywt\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","source":["# img = Image.new(\"RGB\", (512, 512), (0, 0, 0))\n","\n","# # Save the image as a PNG file\n","# img.save(\"/content/drive/MyDrive/Colab Notebooks/Steganography/Black.png\")\n","# img = Image.new(\"RGB\", (512, 512), (255, 255, 255))\n","\n","# # Save the image as a PNG file\n","# img.save(\"/content/drive/MyDrive/Colab Notebooks/Steganography/White.png\")"],"metadata":{"id":"F0Dzeha0W7Jc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# img = Image.open('/content/drive/MyDrive/Colab Notebooks/Steganography/Invert.png')\n","\n","# # Keep only the first 3 channels (red, green, and blue)\n","# img = img.convert('RGB')\n","\n","# # Save the converted 3-channel image\n","# img.save('/content/drive/MyDrive/Colab Notebooks/Steganography/Invert.png')\n","# img = Image.open('/content/drive/MyDrive/Colab Notebooks/Steganography/image.png')\n","\n","# # Keep only the first 3 channels (red, green, and blue)\n","# img = img.convert('RGB')\n","\n","# # Save the converted 3-channel image\n","# img.save('/content/drive/MyDrive/Colab Notebooks/Steganography/image.png')"],"metadata":{"id":"SjRNavhWzFbG"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H2R_S-By1s-L"},"outputs":[],"source":["root_dir = '/content/drive/MyDrive/Colab Notebooks/'\n","dataset_path = os.path.join(root_dir,'Steganography/new_Dataset')\n","\n","train_csv = os.path.join(root_dir,'train_dataset.csv')\n","test_csv = os.path.join(root_dir,'Steganography/validation_dataset.csv')\n","train_folder = os.path.join(dataset_path,'train')\n","validation_folder = os.path.join(dataset_path,'Valid')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CXAM3lgbcaOf"},"outputs":[],"source":["cover = '/content/drive/MyDrive/Colab Notebooks/Steganography/Lion.jpg'\n","secret = '/content/drive/MyDrive/Colab Notebooks/image.png'\n","\n","dataset = [{\n","        'cover_image':cover,\n","        'secret_image':secret\n","    }]\n","dataframe = pd.DataFrame(dataset)\n","cover = Image.open(cover)\n","secret = Image.open(secret)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JnMSTB4b1d6j"},"outputs":[],"source":["%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9w98z0qOpipP"},"outputs":[],"source":["\n","IMG_SIZE = 64\n","LEARNING_RATE  = 0.001\n","COVER_LOSS_WEIGHT = 1\n","SECRET_LOSS_WEIGHT = 1\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 1\n","EPOCHS = 50\n","DECODER_LOSS_WEIGHT = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H5b5sJ8W4TUJ"},"outputs":[],"source":["imagetransformation = {\n","    'train_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE,IMG_SIZE)),torchvision.transforms.ToTensor()]),\n","    'valid_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE,IMG_SIZE)),torchvision.transforms.ToTensor()]),\n","    'test_transforms':torchvision.transforms.Compose([torchvision.transforms.Resize((IMG_SIZE,IMG_SIZE)),torchvision.transforms.ToTensor()])\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4qYPcaAi6S6_"},"outputs":[],"source":["#conversion of image into resized format and return of trnasformed image\n","class SteganoDataset(torch.utils.data.Dataset):\n","    def __init__(self,dataset_csv,transforms,type_of_dataset,size='complete'):\n","        self.dataset = pd.read_csv(dataset_csv)\n","        #self.dataset = dataset_csv\n","        self.dataset = self.dataset.reset_index(drop=True)\n","        if size !='complete':\n","            self.dataset = self.dataset[:2]\n","        self.transforms = transforms\n","        self.type = type_of_dataset\n","    \n","    def __getitem__(self,index):\n","        cover_image = self.dataset.iloc[index]['cover_image']\n","        secret_image = self.dataset.iloc[index]['secret_image']\n","        cover_image = Image.open(os.path.join(dataset_path,'cover',cover_image))\n","        secret_image = Image.open(os.path.join(dataset_path,'secret',secret_image))\n","        transformed_cover_image = self.transforms(cover_image)\n","        transformed_secret_image = self.transforms(secret_image)\n","        return {\n","                'cover_image':transformed_cover_image,\n","                'secret_image':transformed_secret_image,\n","            }\n","        \n","    \n","    def __len__(self):\n","      return len(self.dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOHTdzOVQaYp"},"outputs":[],"source":["class PrepNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=3,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=3,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","    \n","    def forward(self,secret_image):\n","        output_1 = F.relu(self.conv1(secret_image))\n","        output_2 = F.relu(self.conv2(secret_image))\n","        output_3 = F.relu(self.conv3(secret_image))\n","        \n","        concatenated_image = torch.cat([output_1,output_2,output_3],dim=1)\n","        output_4 = F.relu(self.conv4(concatenated_image))\n","        output_5 = F.relu(self.conv5(concatenated_image))\n","        output_6 = F.relu(self.conv6(concatenated_image))\n","        \n","        final_concat_image = torch.cat([output_4,output_5,output_6],dim=1)\n","        return final_concat_image\n","\n","class HidingNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=38,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=38,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=38,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv7 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv8 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv9 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.final_layer = nn.Conv2d(in_channels=35,out_channels=3,kernel_size=(3,3),stride=1,padding=1)\n","        \n","    def forward(self,secret_image,cover_image):\n","        concatenated_secrets = torch.cat([cover_image,secret_image],dim=1)\n","        \n","        output_1 = F.relu(self.conv1(concatenated_secrets))\n","        output_2 = F.relu(self.conv2(concatenated_secrets))\n","        output_3 = F.relu(self.conv3(concatenated_secrets))\n","        concat_1 = torch.cat([output_1,output_2,output_3],dim=1)\n","        \n","        output_4 = F.relu(self.conv4(concat_1))\n","        output_5 = F.relu(self.conv5(concat_1))\n","        output_6 = F.relu(self.conv6(concat_1))\n","        concat_2 = torch.cat([output_4,output_5,output_6],dim=1)\n","        \n","        output_7 = F.relu(self.conv7(concat_2))\n","        output_8 = F.relu(self.conv8(concat_2))\n","        output_9 = F.relu(self.conv9(concat_2))\n","        concat_3 = torch.cat([output_7,output_8,output_9],dim=1)\n","        output_converted_image = F.relu(self.final_layer(concat_3))\n","        \n","        return output_converted_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3Oh5jAVRKXg"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self,prep_network,hiding_network):\n","        super().__init__()\n","        self.prep_network = prep_network\n","        self.hiding_network = hiding_network\n","    \n","    def forward(self,cover_image,secret_image):\n","        encoded_secret_image = self.prep_network(secret_image)\n","        \n","        hidden_image = self.hiding_network(encoded_secret_image,\n","                                           cover_image\n","                                          )\n","#         hidden_image = (0.01**0.5)*torch.randn(hidden_image.size(),device=device)\n","        return hidden_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8pOZbBYRxuX"},"outputs":[],"source":["class RevealNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=3,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=3,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv7 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv8 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv9 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        \n","        self.final_layer = nn.Conv2d(in_channels=35,out_channels=3,kernel_size=(3,3),stride=1,padding=1)    \n","    \n","    def forward(self,hidden_image):\n","        \n","        output_1 = F.relu(self.conv1(hidden_image))\n","        output_2 = F.relu(self.conv2(hidden_image))\n","        output_3 = F.relu(self.conv3(hidden_image))\n","        concat_1 = torch.cat([output_1,output_2,output_3],dim=1)\n","        \n","        output_4 = F.relu(self.conv4(concat_1))\n","        output_5 = F.relu(self.conv5(concat_1))\n","        output_6 = F.relu(self.conv6(concat_1))\n","        concat_2 = torch.cat([output_4,output_5,output_6],dim=1)\n","        \n","        output_7 = F.relu(self.conv7(concat_2))\n","        output_8 = F.relu(self.conv8(concat_2))\n","        output_9 = F.relu(self.conv9(concat_2))\n","        concat_3 = torch.cat([output_7,output_8,output_9],dim=1)\n","        \n","        \n","        output_revealed_image = F.relu(self.final_layer(concat_3))\n","        \n","        return output_revealed_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZk4rMWrSPfG"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self,reveal_network):\n","        super().__init__()\n","        self.reveal_network = reveal_network\n","    \n","    def forward(self,hidden_image):\n","        reveal_image = self.reveal_network(hidden_image)\n","        return reveal_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hstt-fC5Sa1L"},"outputs":[],"source":["class SteganoModel(nn.Module):\n","    def __init__(self,encoder,decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","    \n","    def forward(self,cover_image,secret_image,hidden_image,mode):\n","        if mode == 'full':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = True\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            hidden_image = self.encoder(cover_image,secret_image)\n","            reveal_image = self.decoder(hidden_image)\n","            return hidden_image,reveal_image\n","        elif mode == 'encoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            hidden_image = self.encoder(cover_image,secret_image)\n","            return hidden_image\n","        elif mode == 'decoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = True\n","            \n","            reveal_image = self.decoder(hidden_image)\n","            return reveal_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bDeY53u2Ei9V"},"outputs":[],"source":["\n","# filename = os.path.join(\"/content/drive/MyDrive/Colab_Notebooks/Steganography/Completed_model2.joblib\")\n","# # loaded_model = joblib.load(filename)\n","# joblib.dump(model, filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2220,"status":"ok","timestamp":1676552997609,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"},"user_tz":-345},"id":"I1C7fuPOS4yA","outputId":"14609783-d35a-41ce-dd00-d10c4a30f1f8"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["SteganoModel(\n","  (encoder): Encoder(\n","    (prep_network): PrepNetwork(\n","      (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv2): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv4): Conv2d(35, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv5): Conv2d(35, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv6): Conv2d(35, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    )\n","    (hiding_network): HidingNetwork(\n","      (conv1): Conv2d(38, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv2): Conv2d(38, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv3): Conv2d(38, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv4): Conv2d(35, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv5): Conv2d(35, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv6): Conv2d(35, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv7): Conv2d(35, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv8): Conv2d(35, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv9): Conv2d(35, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (final_layer): Conv2d(35, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n","  (decoder): Decoder(\n","    (reveal_network): RevealNetwork(\n","      (conv1): Conv2d(3, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv2): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv3): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv4): Conv2d(35, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv5): Conv2d(35, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv6): Conv2d(35, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (conv7): Conv2d(35, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv8): Conv2d(35, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","      (conv9): Conv2d(35, 5, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","      (final_layer): Conv2d(35, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    )\n","  )\n",")"]},"metadata":{},"execution_count":17}],"source":["prep_net = PrepNetwork()\n","hiding_network = HidingNetwork()\n","\n","encoder = Encoder(prep_net,hiding_network)\n","\n","reveal_net = RevealNetwork()\n","\n","\n","decoder = Decoder(reveal_net)\n","\n","model = SteganoModel(encoder,decoder)\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvFzF3TJTI5Y"},"outputs":[],"source":["class SteganoLoss(nn.Module):\n","    def __init__(self,cover_weight,secret_weight):\n","        super().__init__()\n","        self.cover_weight = cover_weight\n","        self.secret_weight = secret_weight\n","        \n","    def forward(self,predicted_cover_image,cover_image,\n","               predicted_secret_image_1,secret_image_1):\n","    \n","        cover_loss = self.cover_weight*(F.mse_loss(predicted_cover_image,cover_image))\n","        secret_loss = self.secret_weight*(F.mse_loss(predicted_secret_image_1,secret_image_1)) \n","        return cover_loss + secret_loss\n","\n","class DecoderLoss(nn.Module):\n","    def __init__(self,decoder_loss_weight):\n","        super().__init__()\n","        self.decoder_loss_weight = decoder_loss_weight\n","    \n","    def forward(self,reveal_output,secret_image):\n","        reveal = self.decoder_loss_weight*F.mse_loss(reveal_output,secret_image)\n","        return reveal"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9v52sPcTzPI"},"outputs":[],"source":["\n","# # training_csv_path = os.path.join(dataset_path,train_dataset.csv)\n","# # test_csv_path = os.path.join(dataset_path,test_csv)\n","\n","training_dataset = SteganoDataset('/content/drive/MyDrive/Colab Notebooks/train_dataset.csv',imagetransformation['train_transforms'],'train','complete')\n","# test_dataset = SteganoDataset(training_csv_path,imagetransformation['train_transforms'],'Train','complete')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfWfE_rdcywx"},"outputs":[],"source":["# test_dataset = SteganoDataset(dataframe,imagetransformation['test_transforms'],'Valid')\n","\n","\n","train_data_loader = torch.utils.data.DataLoader(training_dataset, \n","                                                batch_size = TRAIN_BATCH_SIZE, \n","                                                shuffle=True,\n","                                               drop_last = True,\n","                                               num_workers = 0\n","                                               )\n","# valid_data_loader = torch.utils.data.DataLoader(valid_dataset, \n","#                                                 batch_size = VALID_BATCH_SIZE, \n","#                                                 shuffle=True,\n","#                                                 drop_last = True,\n","#                                                 num_workers = 0\n","#                                                )\n","                                               \n","# test_data_loader = torch.utils.data.DataLoader(test_dataset, \n","#                                                 batch_size = VALID_BATCH_SIZE, \n","#                                                 shuffle=True,\n","#                                                 drop_last = True,\n","#                                                 num_workers = 0\n","#                                                )\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hvQLeCfjyug"},"outputs":[],"source":["\n","full_model_criterion = SteganoLoss(SECRET_LOSS_WEIGHT,COVER_LOSS_WEIGHT)\n","\n","full_model_optimizer = torch.optim.Adam(model.parameters(),lr=LEARNING_RATE)\n","\n","decoder_criterion = DecoderLoss(DECODER_LOSS_WEIGHT)\n","training_full_model_loss_list = []\n","decoder_loss_list = []\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sZVmw3xWUFum"},"outputs":[],"source":["\n","def train(model,epochs,decoder_criterion,full_model_optimizer,full_model_criterion,learning_rate,training_iterator):\n","    print_every=1\n","    counter=1\n","    for epoch in range(epochs):\n","        for index,training_dict in enumerate(training_iterator):\n","            cover_image = training_dict['cover_image']\n","            cover_image = cover_image.to(device)\n","\n","            secret_image = training_dict['secret_image']\n","            secret_image = secret_image.to(device)\n","\n","            \n","            full_model_optimizer.zero_grad()\n","\n","            encoder_output = model(cover_image,secret_image,secret_image,'encoder')\n","\n","            hidden_image,reveal_image = model(cover_image,secret_image,secret_image,\n","                                                                'full')\n","\n","            full_model_loss = full_model_criterion(hidden_image,cover_image,\n","                             reveal_image,secret_image\n","                            )\n","            full_model_loss.backward()\n","            full_model_optimizer.step()\n","\n","            full_model_optimizer.zero_grad()\n","            reveal_output = model(cover_image,secret_image,\n","                                                                 encoder_output,'decoder')\n","            decoder_loss = decoder_criterion(reveal_output,secret_image)\n","\n","            decoder_loss.backward()\n","            full_model_optimizer.step()\n","            \n","\n","        training_full_model_loss_list.append(full_model_loss)\n","        decoder_loss_list.append(decoder_loss)\n","        if epoch % print_every == 0:\n","            print(\"Training full model loss at {} epochs is: {}\".format(epoch, full_model_loss))\n","            print(\"Training decoder loss at {} epochs is: {}\".format(epoch, decoder_loss))\n","\n","    return model, training_full_model_loss_list,decoder_loss_list\n"]},{"cell_type":"markdown","metadata":{"id":"rE94MW8u5_2n"},"source":["Training full model loss at 0 epochs is: 0.14862200617790222\n","Training decoder loss at 0 epochs is: 0.056159209460020065\n","Training full model loss at 50 epochs is: 0.010316253639757633\n","Training decoder loss at 50 epochs is: 0.006905762478709221\n","Training full model loss at 100 epochs is: 0.005915718153119087\n","Training decoder loss at 100 epochs is: 0.004135390743613243\n","Training full model loss at 150 epochs is: 0.00597141869366169\n","Training decoder loss at 150 epochs is: 0.003256219904869795\n","Training full model loss at 200 epochs is: 0.004562869668006897\n","Training decoder loss at 200 epochs is: 0.0032390698324888945\n","Training full model loss at 250 epochs is: 0.004033954814076424\n","Training decoder loss at 250 epochs is: 0.00324784847907722\n","Training full model loss at 300 epochs is: 0.0028372027445584536\n","Training decoder loss at 300 epochs is: 0.002142705488950014\n","Training full model loss at 350 epochs is: 0.003511040238663554\n","Training decoder loss at 350 epochs is: 0.0028315880335867405\n","Training full model loss at 400 epochs is: 0.006889783777296543\n","Training decoder loss at 400 epochs is: 0.006818610243499279\n","Training full model loss at 450 epochs is: 0.0030810432508587837\n","Training decoder loss at 450 epochs is: 0.0027422530110925436\n","Training full model loss at 500 epochs is: 0.0026186055038124323\n","Training decoder loss at 500 epochs is: 0.00222468632273376\n","Training full model loss at 550 epochs is: 0.0022935508750379086\n","Training decoder loss at 550 epochs is: 0.0016986110713332891\n","Training full model loss at 600 epochs is: 0.0017199815483763814\n","Training decoder loss at 600 epochs is: 0.0012137810699641705\n","Training full model loss at 650 epochs is: 0.002981864381581545\n","Training decoder loss at 650 epochs is: 0.002139737131074071\n","Training full model loss at 700 epochs is: 0.00157183688133955\n","Training decoder loss at 700 epochs is: 0.0011825517285615206\n","Training full model loss at 750 epochs is: 0.001144192647188902\n","Training decoder loss at 750 epochs is: 0.0006921886233612895\n","Training full model loss at 800 epochs is: 0.0016071755671873689\n","Training decoder loss at 800 epochs is: 0.0011148437624797225\n","Training full model loss at 850 epochs is: 0.0016389719676226377\n","Training decoder loss at 850 epochs is: 0.0010738647542893887\n","Training full model loss at 900 epochs is: 0.0011910195462405682\n","Training decoder loss at 900 epochs is: 0.0007727841730229557\n","Training full model loss at 950 epochs is: 0.0011191064259037375\n","Training decoder loss at 950 epochs is: 0.0007212755153886974"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Zo_lYACU0o9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a67acdaf-1fe6-4381-acfb-b8f2ce018bca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training full model loss at 0 epochs is: 0.022608328610658646\n","Training decoder loss at 0 epochs is: 0.012703999876976013\n","Training full model loss at 1 epochs is: 0.0207536444067955\n","Training decoder loss at 1 epochs is: 0.006840317510068417\n","Training full model loss at 2 epochs is: 0.012308981269598007\n","Training decoder loss at 2 epochs is: 0.006615716498345137\n","Training full model loss at 3 epochs is: 0.012842878699302673\n","Training decoder loss at 3 epochs is: 0.009576262906193733\n","Training full model loss at 4 epochs is: 0.013819294050335884\n","Training decoder loss at 4 epochs is: 0.007165811024606228\n","Training full model loss at 5 epochs is: 0.012649396434426308\n","Training decoder loss at 5 epochs is: 0.006015503313392401\n","Training full model loss at 6 epochs is: 0.013923462480306625\n","Training decoder loss at 6 epochs is: 0.009581430815160275\n","Training full model loss at 7 epochs is: 0.007849170826375484\n","Training decoder loss at 7 epochs is: 0.005018238909542561\n","Training full model loss at 8 epochs is: 0.010472362861037254\n","Training decoder loss at 8 epochs is: 0.00620428379625082\n","Training full model loss at 9 epochs is: 0.007418741937726736\n","Training decoder loss at 9 epochs is: 0.004008980467915535\n","Training full model loss at 10 epochs is: 0.006960081867873669\n","Training decoder loss at 10 epochs is: 0.003765094093978405\n","Training full model loss at 11 epochs is: 0.019330337643623352\n","Training decoder loss at 11 epochs is: 0.014429055154323578\n"]}],"source":["model, training_full_model_loss_list, decoder_loss_list = train(model, EPOCHS,decoder_criterion, full_model_optimizer, full_model_criterion, LEARNING_RATE, train_data_loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3Wi8qChAmE_p"},"outputs":[],"source":["# filename = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Steganography/stegomodeltest500.pkl\")\n","# # loaded_model = joblib.load(filename)\n","# torch.save(model,filename)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBkKVTiRm3Vx"},"outputs":[],"source":["model = torch.load('/content/drive/MyDrive/Colab Notebooks/Steganography/stegomodeltest.pkl',map_location=torch.device('cpu'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xU1b58w-YKxo"},"outputs":[],"source":["\n","def predict(model,iterator,mode):\n","\n","    predict_dict = next(iter(iterator))\n","    cover_image = predict_dict['cover_image']\n","    # print(cover_image)\n","    cover_image = cover_image.to(device)\n","    secret_image_1 = predict_dict['secret_image']\n","    secret_image_1 = secret_image_1.to(device)\n","\n","    model.eval()\n","\n","    if mode =='test':\n","      arnold = Arnold(6, 40, 33)\n","      coeffs, image = wtransform(cover_image[0].permute(1,2,0))\n","      soeffs, simage = wtransform(secret_image_1[0].permute(1,2,0))\n","      temp = [[],[],[]]\n","      coeff, cA, cH, cV, cD, soeff, sA, sH, sV, sD = [temp[:] for i in range(10)]\n","      \n","      # cA = arnold.applyTransformTo(cA)\n","      # cA = arnold.applyInverseTransformTo(cA)\n","      for ch in range(3):\n","        [(cA[ch], (cH[ch], cV[ch], cD[ch]))] = coeffs[ch]\n","        [(sA[ch], (sH[ch], sV[ch], sD[ch]))] = soeffs[ch]\n","        # coeff[ch]= [(cA, (cH, cV, cD))]\n","      \n","      cAA = torch.from_numpy(np.stack((cA[0], cA[1], cA[2]), axis=-1)).reshape(*cover_image.shape).to(device)\n","      cHH = torch.from_numpy(np.stack((cH[0], cH[1], cH[2]), axis=-1)).reshape(*cover_image.shape).to(device)\n","      cVV = torch.from_numpy(np.stack((cV[0], cV[1], cV[2]), axis=-1)).reshape(*cover_image.shape).to(device)\n","      cDD = torch.from_numpy(np.stack((cD[0], cD[1], cD[2]), axis=-1)).reshape(*cover_image.shape).to(device)\n","\n","      sAA = torch.from_numpy(np.stack((sA[0], sA[1], sA[2]), axis=-1)).reshape(*secret_image_1.shape).to(device)\n","      sHH = torch.from_numpy(np.stack((sH[0], sH[1], sH[2]), axis=-1)).reshape(*secret_image_1.shape).to(device)\n","      sVV = torch.from_numpy(np.stack((sV[0], sV[1], sV[2]), axis=-1)).reshape(*secret_image_1.shape).to(device)\n","      sDD = torch.from_numpy(np.stack((sD[0], sD[1], sD[2]), axis=-1)).reshape(*secret_image_1.shape).to(device)\n"," \n","      hA,rA= model(cAA,sAA,sAA,'full')\n","      hH,rH= model(cHH,sHH,sHH,'full')\n","      hV,rV= model(cVV,sVV,sVV,'full')\n","      hD,rD= model(cDD,sDD,sDD,'full')\n","\n","      rA = rA.to(torch.device('cpu')).detach().to(torch.long)[0].permute(1,2,0).numpy()\n","      rH = rH.to(torch.device('cpu')).detach().to(torch.long)[0].permute(1,2,0).numpy()\n","      rV = rV.to(torch.device('cpu')).detach().to(torch.long)[0].permute(1,2,0).numpy()\n","      rD = rD.to(torch.device('cpu')).detach().to(torch.long)[0].permute(1,2,0).numpy()\n","\n","      # rA= model(hH,hH,hH,'decoder')[0].permute(1,2,0).detach().numpy()\n","      # rH= model(hH,hH,hH,'decoder')[0].permute(1,2,0).detach().numpy()\n","      # rV= model(hV,hV,hV,'decoder')[0].permute(1,2,0).detach().numpy()\n","      # rD= model(hD,hD,hD,'decoder')[0].permute(1,2,0).detach().numpy()\n","      # rA = rA * 255\n","      # rA = rA.to(torch.device('cpu'))\n","      # rA = rA.detach().to(torch.long)\n","      # rA = rA[0].permute(1,2,0).numpy()\n","      # im = Image.fromarray(r.astype(np.uint8))\n","      # im.save(\"revealed.png\")\n","\n","      # print(hA)\n","      # print(\"latest\")\n","      # print(rA)\n","      for ch in range(3):\n","        soeff[ch]= [(rA[:,:,ch], (rH[:,:,ch], rV[:,:,ch], rD[:,:,ch]))]\n","     \n","    # test = Image.fromarray(np.uint8(cAA))\n","    # test.save(\"test.png\")\n","      reveal_image_1 = iwtransform(soeff,image)\n","      print(np.array(reveal_image_1))\n","      reveal_image_1.save(\"new.png\")\n","    if mode =='decoder':\n","      \n","      reveal_image_1= model(cover_image,cover_image,cover_image,mode)\n","      \n","      # dot_graph = torchviz.make_dot(model(cover_image,cover_image,cover_image,mode))\n","      # dot_graph.render(\"decoder.dot\")\n","    elif mode =='encoder':\n","      hidden_image= model(cover_image,secret_image_1,secret_image_1,mode)\n","      # dot_graph = torchviz.make_dot(model(cover_image,secret_image_1,secret_image_1,mode))\n","      # dot_graph.render(\"encoder.dot\")\n","    elif mode == \"full\":\n","      hidden_image,reveal_image_1= model(cover_image,secret_image_1,secret_image_1,mode)\n","      # dot_graph = torchviz.make_dot(model(cover_image,secret_image_1,secret_image_1,mode))\n","      # dot_graph.render(\"full.dot\")\n","      cover_image = cover_image * 255\n","      cover_image = cover_image.to(torch.device('cpu'))\n","      cover_image = cover_image.detach().to(torch.long)\n","      secret_image_1 = secret_image_1 * 255\n","      secret_image_1 = secret_image_1.to(torch.device('cpu'))\n","      secret_image_1 = secret_image_1.detach().to(torch.long)\n","    if mode =='encoder' or mode == 'full':\n","      hidden_image[hidden_image>1] = 1\n","      hidden_image = hidden_image * 255\n","      hidden_image = hidden_image.to(torch.device('cpu'))\n","      hidden_image = hidden_image.detach().to(torch.long)\n","      h = hidden_image[0].permute(1,2,0).numpy()\n","      im = Image.fromarray(h.astype(np.uint8))\n","      im.save(\"/content/drive/MyDrive/Colab Notebooks/stego_img.png\")\n","      if mode == 'encoder': return h\n","    if mode =='decoder' or mode == 'full':\n","      reveal_image_1[reveal_image_1>1] = 1\n","      reveal_image_1 = reveal_image_1 * 255\n","      reveal_image_1 = reveal_image_1.to(torch.device('cpu'))\n","      reveal_image_1 = reveal_image_1.detach().to(torch.long)\n","      r = reveal_image_1[0].permute(1,2,0).numpy()\n","      im = Image.fromarray(r.astype(np.uint8))\n","      im.save(\"/content/drive/MyDrive/Colab Notebooks/revealed.png\")\n","      if mode == 'encoder': return r\n","    return {\n","        'cover_image_grid':cover_image[0].permute(1,2,0).numpy(),\n","        'secret_image_1_grid':secret_image_1[0].permute(1,2,0).numpy(),\n","        'hidden_image_grid':h,\n","        'reveal_image_1_grid':r,\n","    }\n","grids = predict(model,test_data_loader,'full')"]},{"cell_type":"code","source":["# grids['cover_image_grid'] = arnold.applyInverseTransformTo(grids['cover_image_grid'])\n","# grids['hidden_image_grid'] = arnold.applyInverseTransformTo(grids['hidden_image_grid'])"],"metadata":{"id":"0B_YuKsGLr91"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3SIZqG9NWnOe"},"outputs":[],"source":["plot(grids)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GuQOu96oQAed"},"outputs":[],"source":["import pickle\n","import torchviz\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwxM31L4QCoW"},"outputs":[],"source":["!pip install torchviz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbm-ZBmXV3aw"},"outputs":[],"source":["!apt-get install -y graphviz\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgLwNLzAWAbe"},"outputs":[],"source":["!dot -Tpng full.dot -o full.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bpNXpNaAZGOj"},"outputs":[],"source":["!dot -Tpng encoder.dot -o encodermodel.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ozq3kymAZegG"},"outputs":[],"source":["!dot -Tpng decoder.dot -o decodermodel.png"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bgOJsRxiVjjH"},"outputs":[],"source":["torchviz.render(model, \"model.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ejQRClCccysX"},"outputs":[],"source":["# def predict(cover,model=test):\n","#   mode='decoder'\n","#   cover=torchvision.transforms.Compose([torchvision.transforms.Resize((512,512)),torchvision.transforms.ToTensor(cover)])\n","#   cover = cover.to(device)\n","#   model.eval()\n","#   reveal_image_1= model(cover,cover,cover,mode)\n","#   reveal_image_1[reveal_image_1>1] = 1\n","#   reveal_image_1 = reveal_image_1 * 255\n","#   reveal_image_1 = reveal_image_1.to(torch.device('cpu'))\n","#   reveal_image_1 = reveal_image_1.detach().to(torch.long)\n","#   r = reveal_image_1[0].permute(1,2,0).numpy()\n","#   im = Image.fromarray(r.astype(np.uint8))\n","#   return im"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s7FdUR-Bqe2J"},"outputs":[],"source":["from torchvision.utils import save_image\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K0ioALQYWSwe"},"outputs":[],"source":["def plot(grids):\n","    plt.figure(figsize=(15,8))\n","    \n","    plt.subplot(241)\n","    plt.title('Cover Image')\n","    plt.imshow(grids['cover_image_grid'])\n","\n","    plt.subplot(242)\n","    plt.title('Secret Image')\n","    plt.imshow(grids['secret_image_1_grid'])\n","\n","    plt.subplot(245)\n","    plt.title('Hidden Image')\n","    plt.imshow(grids['hidden_image_grid'])\n","    \n","    plt.subplot(246)\n","    plt.title('Reveal Image')\n","    plt.imshow(grids['reveal_image_1_grid'])\n","\n","    plt.savefig('/content/drive/MyDrive/Colab Notebooks/Plot.png')\n","    plt.show()\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzHpnf22U2vD"},"outputs":[],"source":["'''\n","data = next(iter(test_data_loader))\n","\n","cover_image = data['cover_image']\n","cover_image = cover_image.to(device)\n","\n","secret_image_1 = data['secret_image']\n","secret_image_1 = secret_image_1.to(device)\n","\n","model.eval()\n","    \n","hidden_image,reveal_image_1 = model(cover_image,secret_image_1,secret_image_1,'full')\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5MDSPFzuVIXM"},"outputs":[],"source":["#make_dot(hidden_image).render('hidden_image',format='png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g3GlMMmYVNKx"},"outputs":[],"source":["#make_dot(reveal_image_1).render('reveal_image',format='png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"woB2-YkIVSeo"},"outputs":[],"source":["\n","def plot_loss(loss_list,num):\n","    plt.plot(torch.tensor(loss_list, device = 'cpu'))\n","    if(num==1):\n","      plt.title('full mode loss')\n","      plt.xlabel(\"epochs\")\n","      plt.ylabel(\"loss\")\n","      plt.savefig('/content/drive/MyDrive/Colab Notebooks/fullmodeloss11.png')\n","      plt.show()\n","    else:\n","      plt.title('decoder loss')\n","      plt.xlabel(\"epochs\")\n","      plt.ylabel(\"loss\")\n","      plt.savefig('/content/drive/MyDrive/Colab Notebooks/decoderloss11.png')\n","      plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2ztDFJYfVTb5"},"outputs":[],"source":["plot_loss(training_full_model_loss_list,1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WNk5S83VVWOf"},"outputs":[],"source":["plot_loss(decoder_loss_list,2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6hg_MrhWsI6"},"outputs":[],"source":["\n","for i in range(5):\n","    grids = predict(test,test_data_loader,'full')\n","    plot(grids)\n"]},{"cell_type":"code","source":["def wtransform(img):\n","  image = np.array(img)\n","  coeffs = [[],[],[]]\n","\n","  for ch in range(3):\n","    # Perform wavelet transform\n","    coeffs[ch] = pywt.swt2(image[:,:,ch], 'haar',level=1)\n","  return coeffs, image\n","def iwtransform(coeffs,image):\n","  image[:,:,0] = pywt.iswt2(coeffs[0], 'haar')\n","  image[:,:,1] = pywt.iswt2(coeffs[1], 'haar')\n","  image[:,:,2] = pywt.iswt2(coeffs[2], 'haar')\n","  return Image.fromarray(np.uint8(image))"],"metadata":{"id":"J0tiuDd6l9rM"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fGtxtCQxyYM9"},"outputs":[],"source":["from matplotlib.image import imread\n","import matplotlib.pyplot as plt\n","import pywt\n","plt.rcParams['figure.figsize'] = [16, 16]\n","plt.rcParams.update({'font.size': 18})\n","\n","A = Image.open('/content/drive/MyDrive/Colab Notebooks/Steganography/NikeshC.jpg')\n","print(type(A))\n","B = np.mean(A, -1); # Convert RGB to grayscale\n","\n","n = 1\n","w = 'db1'\n","coeff = [[],[]]\n","arr = [[],[],[]]\n","coeff_slices = [[],[],[]]\n","for ch in range(3):\n","  coeffs = pywt.swt2(A[:,:,ch],wavelet=w,level=n)\n","  # data = np.zeros_like(A)\n","  # print(data.shape)\n","  # print(coeffs[0])\n","  # coeffs[1] = pywt.wavedec2(A[:,:,1],wavelet=w,level=n)\n","  # coeffs[2] = pywt.wavedec2(A[:,:,2],wavelet=w,level=n)\n","\n","  # normalize each coefficient array\n","  \n","  coeff[0] = coeffs[0][0] / np.abs(coeffs[0][0]).max()\n","  for detail_level in range(n):\n","      coeff[detail_level + 1] = [d/np.abs(d).max() for d in coeffs[0][detail_level + 1]]\n","\n","  arr[ch], coeff_slices[ch] = np.array(pywt.coeffs_to_array(coeff))\n","\n","final_img = np.dstack([arr[0]*255, arr[1]*255, arr[2]*255]).astype(np.uint8)\n","print(final_img.shape)\n","\n","# a = arr[coeff_slices[1]['dd']]\n","plt.imshow(final_img,cmap='gray',vmin=-0.25,vmax=0.75)\n","plt.savefig('/content/drive/MyDrive/Colab Notebooks/Plotwave4.png')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQsCDAUSljqp"},"outputs":[],"source":["\n","r_np = imread('/content/drive/MyDrive/Colab Notebooks/Plotwave2.png')\n","g_np = imread('/content/drive/MyDrive/Colab Notebooks/Plotwave3.png')\n","b_np = imread('/content/drive/MyDrive/Colab Notebooks/Plotwave4.png')\n","\n","\n","# Add the channels to the final image\n","final_img = np.dstack([b_np[:,:,0], g_np[:,:,2], r_np[:,:,2]]).astype(np.uint8)\n","\n","print(final_img.shape)\n","plt.imshow(final_img, interpolation='nearest')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GkPOtNqJ30NA"},"outputs":[],"source":["import numpy as np\n","import math, time, sys\n","from PIL import Image\n","class Arnold:\n","\n","    def __init__(self, a:int, b:int, rounds:int):\n","        # Parameters\n","        self.a = a\n","        self.b = b\n","        self.rounds = rounds\n","\n","    def mapping(self, s:np.shape):\n","        x, y = np.meshgrid(range(s[0]), range(s[0]), indexing=\"ij\")\n","        xmap = (self.a*self.b*x + x + self.a*y) % s[0]\n","        ymap = (self.b*x + y) % s[0]\n","        return xmap, ymap\n","\n","    def inverseMapping(self, s:np.shape):\n","        x, y = np.meshgrid(range(s[0]), range(s[0]), indexing=\"ij\")\n","        xmap = (x - self.a*y) % s[0]\n","        ymap = (-self.b*x + self.a*self.b*y + y) % s[0]\n","        return xmap, ymap\n","\n","    def applyTransformTo(self, image:np.ndarray):\n","        xm, ym = self.mapping(image.shape)\n","        img = image\n","        for r in range(self.rounds):\n","            img = img[xm, ym]\n","        return img\n","\n","    def applyInverseTransformTo(self, image:np.ndarray):\n","        xm, ym = self.inverseMapping(image.shape)\n","        img = image\n","        for r in range(self.rounds):\n","          img = img[xm, ym]\n","        return img"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hczxr-re4FaQ"},"outputs":[],"source":["\n","image_path = \"/content/drive/MyDrive/Colab Notebooks/Steganography/Nikesh.jpg\"\n","\n","# Arnold Transform Parameters\n","a = 6\n","b = 40\n","rounds = 33\n","\n","# Open the images\n","lena = np.array(Image.open(image_path))\n","\n","print(\" ~~~~  * PARAMETERS *  ~~~~ \")\n","arnold = Arnold(a, b, rounds)\n","print(\"\\ta:\\t\", a)\n","print(\"\\tb:\\t\", b)\n","print(\"\\trounds:\\t\", rounds)\n","\n","print(\"\\n ~~~~  *  RESULTS   *  ~~~~ \")\n","\n","start_time = time.time()\n","scrambled = arnold.applyTransformTo(lena)\n","exec_time = time.time() - start_time\n","print(\"Transform  execution time: %.6f \" % exec_time, \"sec\")\n","im = Image.fromarray(scrambled)\n","im.save(\"/content/drive/MyDrive/Colab Notebooks/Steganography/scrambledInvert.png\", format=\"PNG\")\n","\n","start_time = time.time()\n","reconstructed = arnold.applyInverseTransformTo(scrambled)\n","exec_time = time.time() - start_time\n","print(\"Inverse T. execution time: %.6f \" % exec_time, \"sec\")\n","im = Image.fromarray(reconstructed)\n","im.save(\"/content/drive/MyDrive/Colab Notebooks/reconstructed\", format=\"PNG\")\n"]},{"cell_type":"markdown","metadata":{"id":"R0nhU_A_2_RC"},"source":["<h1>Analysis Code</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G5xzk706290W"},"outputs":[],"source":["import math\n","import numpy as np\n","import cv2\n","from matplotlib.image import imread\n","from scipy.stats import entropy\n","import matplotlib.pyplot as plt\n","\n","def psnr(img1, img2):\n","    mse = np.mean((img1 - img2) ** 2)\n","    if mse == 0:\n","        return float('inf')\n","    PIXEL_MAX = 255.0\n","    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n","\n","def snr(stego_image, original_image):\n","    # Calculate the noise image\n","    noise_image = stego_image - original_image\n","    # Calculate the average noise power\n","    noise_power = np.mean(noise_image ** 2)\n","    # Calculate the average signal power\n","    signal_power = np.mean(original_image ** 2)\n","    # Calculate the SNR\n","    snr = signal_power / noise_power\n","    # Convert the SNR to decibels\n","    snr_db = 10 * np.log10(snr)\n","    return snr_db\n","\n","def ssim(image1, image2):\n","    # Convert the images to grayscale\n","    image1_gray = cv2.cvtColor(cv2.convertScaleAbs(image1), cv2.COLOR_BGR2GRAY)\n","    image2_gray = cv2.cvtColor(cv2.convertScaleAbs(image2), cv2.COLOR_BGR2GRAY)\n","    # Calculate the SSIM\n","    ssim, _ = cv2.quality.QualityMSE_compute(image1_gray, image2_gray)\n","    return ssim\n","\n","def correlation_coefficient(image1, image2):\n","    # Flatten the images into 1D arrays\n","    image1_flat = image1.flatten()\n","    image2_flat = image2.flatten()\n","    # Calculate the correlation coefficient\n","    correlation = np.corrcoef(image1_flat, image2_flat)[0, 1]\n","    return correlation\n","\n","def image_entropy(image):\n","    # Flatten the image into a 1D array\n","    image_flat = image.flatten()\n","    # Calculate the entropy\n","    return entropy(image_flat)\n","\n","def pixel_frequencies(image):\n","    # Flatten the image into a 1D array\n","    image_flat = image.flatten()\n","    # Calculate the frequencies of each pixel value\n","    unique, counts = np.unique(image_flat, return_counts=True)\n","    frequencies = counts / len(image_flat)\n","    return unique, frequencies,counts\n","\n","def plot_frequencies(unique, frequencies,counts):\n","    # Plot the frequencies\n","    plt.plot(unique, counts)\n","    plt.xlim([0, 256])\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"27Cwoaon2sGP"},"source":["<h1>For Loop</h1>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EdBjAvLa22Eb"},"outputs":[],"source":["cover = Image.open(cover)\n","secret = Image.open(secret)\n","grids = predict(model,test_data_loader,'full')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i9fSboe34EMg"},"outputs":[],"source":["cpath = '/content/drive/MyDrive/Colab Notebooks/Steganography/Dataset/cover'\n","spath = '/content/drive/MyDrive/Colab Notebooks/Steganography/Dataset/train'\n","listofcimg = os.listdir(cpath)\n","listofsimg = os.listdir(spath)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p70UwYO63Xms"},"outputs":[],"source":["df = pd.DataFrame(columns=[\"psnrC\", \"psnrS\", \"snrC\", \"snrS\", \"ssimC\", \"ssimS\", \"corrC\", \"corrS\", \"entC\", \"entH\", \"entS\", \"entR\"])\n","for i in range(1000):\n","  dataset = [{\n","        'cover_image':os.path.join(cpath,listofcimg[i]),\n","        'secret_image':os.path.join(spath,listofsimg[i])\n","    }]\n","  dataframe = pd.DataFrame(dataset)\n","  test_dataset = SteganoDataset(dataframe,imagetransformation['test_transforms'],'Valid')                                               \n","  test_data_loader = torch.utils.data.DataLoader(test_dataset, \n","                                                  batch_size = VALID_BATCH_SIZE, \n","                                                  shuffle=True,\n","                                                  drop_last = True,\n","                                                  num_workers = 0\n","                                                )\n","\n","  grids = predict(model,test_data_loader,'full')\n","  psnrC = psnr(grids['cover_image_grid'],grids['hidden_image_grid'])\n","  psnrS = psnr(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])\n","  snrC = snr(grids['cover_image_grid'],grids['hidden_image_grid'])\n","  snrS = snr(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])\n","  ssimC = ssim(grids['cover_image_grid'],grids['hidden_image_grid'])[0]\n","  ssimS = ssim(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])[0]\n","  corrC = correlation_coefficient(grids['cover_image_grid'],grids['hidden_image_grid'])\n","  corrS = correlation_coefficient(grids['secret_image_1_grid'],grids['reveal_image_1_grid'])\n","  entC = image_entropy(grids['cover_image_grid'])\n","  entH = image_entropy(grids['hidden_image_grid'])\n","  entS = image_entropy(grids['secret_image_1_grid'])\n","  entR = image_entropy(grids['reveal_image_1_grid'])\n","  df = df.append({\"psnrC\": psnrC, \"psnrS\": psnrS, \"snrC\": snrC, \"snrS\": snrS, \"ssimC\": ssimC, \"ssimS\": ssimS, \"corrC\": corrC, \"corrS\": corrS, \"entC\": entC, \"entH\": entH, \"entS\": entS, \"entR\": entR}, ignore_index=True)\n","\n","df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Steganography/table.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R4_GrppXTcC9"},"outputs":[],"source":["df_norm = df.apply(lambda x: (x - x.mean()) / x.std())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4w-EDbR2P1Nd"},"outputs":[],"source":["df.plot(y='psnrS')\n","plt.xlabel(\"Image number\")\n","plt.ylabel(\"PSNR\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FaBTcnhVQYHQ"},"outputs":[],"source":["import seaborn as sns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgnMEBp6Qcij"},"outputs":[],"source":["sns.heatmap(df.corr())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yqMDc2YvSERO"},"outputs":[],"source":["df.mean(axis=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4SdFQixvgiAp"},"outputs":[],"source":["from skimage.metrics import structural_similarity as ssim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fYKOHFwXhIDx"},"outputs":[],"source":["ssimValue = ssim(grids['cover_image_grid'],grids['secret_image_1_grid'],win_size=11, multichannel = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SRmWeeuNirtY"},"outputs":[],"source":["ssimValue"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQh2JJ0uj-hI"},"outputs":[],"source":["from pyssim import SSIM \n","ssim = SSIM()\n","score = ssim.compute(grids['cover_image_grid'],grids['secret_image_1_grid'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oicWsTn2kkG2"},"outputs":[],"source":["!pip install pyssim"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}