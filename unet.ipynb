{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHDZYDsiNutkFP+KC9rKQH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"fX5tFGIvmTI_"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        self.down_conv1 = self.double_conv(3, 6)\n","        self.down_conv2 = self.double_conv(64, 128)\n","        self.down_conv3 = self.double_conv(128, 256)\n","        self.down_conv4 = self.double_conv(256, 512)\n","        self.down_conv5 = self.double_conv(512, 1024)\n","\n","        self.up_conv1 = self.deconv(1024, 512)\n","        self.up_conv2 = self.double_conv(1024, 256)\n","        self.up_conv3 = self.double_conv(512, 128)\n","        self.up_conv4 = self.double_conv(256, 64)\n","        self.up_conv5 = nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1)\n","\n","    def double_conv(self, in_channels, out_channels):\n","        conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","        return conv\n","\n","    def deconv(self, in_channels, out_channels):\n","        deconv = nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","        return deconv\n","\n","    def forward(self, x):\n","        # Encoding path\n","        x1 = self.down_conv1(x)\n","        x2 = self.down_conv2(x1)\n","        x3 = self.down_conv3(x2)\n","        x4 = self.down_conv4(x3)\n","        x5 = self.down_conv5(x4)\n","\n","        # Decoding path\n","        x = self.up_conv1(x5)\n","        x = torch.cat([x, x4], dim=1)\n","        x = self.up_conv2(x)\n","        x = torch.cat([x, x3], dim=1)\n","        x = self.up_conv3(x)\n","        x = torch.cat([x, x2], dim=1)\n","        x = self.up_conv4(x)\n","        x = torch.cat([x, x1], dim=1)\n","        x = self.up_conv5(x)\n","        x = torch.sigmoid(x)\n","\n","        return x\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pywt\n","\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","        self.down_conv1 = self.double_conv(3, 64)\n","        self.down_conv2 = self.double_conv(64, 128)\n","        self.down_conv3 = self.double_conv(128, 256)\n","        self.down_conv4 = self.double_conv(256, 512)\n","        self.down_conv5 = self.double_conv(512, 1024)\n","\n","        self.up_conv1 = self.deconv(1024, 512)\n","        self.up_conv2 = self.double_conv(1024, 256)\n","        self.up_conv3 = self.double_conv(512, 128)\n","        self.up_conv4 = self.double_conv(256, 64)\n","        self.up_conv5 = nn.ConvTranspose2d(128, 3, kernel_size=4, stride=2, padding=1)\n","\n","    def double_conv(self, in_channels, out_channels):\n","        conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(0.2, inplace=True),\n","        )\n","        return conv\n","\n","    def deconv(self, in_channels, out_channels):\n","        deconv = nn.Sequential(\n","            nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True),\n","        )\n","        return deconv\n","\n","    def forward(self, x):\n","        # Wavelet transform of the secret image\n","        coeffs = pywt.dwt2(x, 'haar')\n","        cA, (cH, cV, cD) = coeffs\n","\n","        # Encoding path\n","        x1 = self.down_conv1(x)\n","        x2 = self.down_conv2(x1)\n","        x3 = self.down_conv3(x2)\n","        x4 = self.down_conv4(x3)\n","        x5 = self.down_conv5(x4)\n","\n","        # Decoding path\n","        x = self.up_conv1(x5)\n","        x = torch.cat([x, x4], dim=1)\n","        x = self.up_conv2(x)\n","        x = torch.cat([x, x3], dim=1)\n","        x = self.up_conv3(x)\n","        x = torch.cat([x, x2], dim=1)\n","        x = self.up_conv4(x)\n","        x = torch.cat([x, x1], dim=1)\n","        x = self.up_conv5(x)\n","\n","        # Inverse wavelet transform of the secret image\n","        x = torch.cat([cA, x], dim=1)\n","        x = torch.cat([x, cH, cV, cD], dim=1)\n","        x = pywt.idwt2(x, 'haar')\n","\n","        x = torch.sigmoid(x)\n","\n","        return x\n"],"metadata":{"id":"wf1C3-rCmfRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","# Load carrier image and secret image\n","carrier = cv2.imread('carrier_image.png')\n","secret = cv2.imread('secret_image.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Convert to PyTorch tensors and normalize\n","carrier = torch.from_numpy(carrier).permute(2, 0, 1).float() / 255\n","secret = torch.from_numpy(secret).unsqueeze(0).unsqueeze(0).float() / 255\n","\n","# Instantiate UNet model and pass secret image through it\n","unet = UNet()\n","output = unet(secret)\n","\n","# Convert output back to numpy array and save as image\n","output = output.detach().numpy().squeeze()\n","output = (output * 255).clip(0, 255).astype(np.uint8)\n","cv2.imwrite('output_image.png', output)\n"],"metadata":{"id":"35qqCdFhmujg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Define the UNet model\n","class UNet(nn.Module):\n","    def __init__(self):\n","        super(UNet, self).__init__()\n","\n","        # Define encoder layers\n","        self.conv1 = nn.Conv2d(1, 64, 4, stride=2, padding=1)\n","        self.bn1 = nn.BatchNorm2d(64)\n","        self.conv2 = nn.Conv2d(64, 128, 4, stride=2, padding=1)\n","        self.bn2 = nn.BatchNorm2d(128)\n","        self.conv3 = nn.Conv2d(128, 256, 4, stride=2, padding=1)\n","        self.bn3 = nn.BatchNorm2d(256)\n","        self.conv4 = nn.Conv2d(256, 512, 4, stride=2, padding=1)\n","        self.bn4 = nn.BatchNorm2d(512)\n","        self.conv5 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n","        self.bn5 = nn.BatchNorm2d(512)\n","        self.conv6 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n","        self.bn6 = nn.BatchNorm2d(512)\n","        self.conv7 = nn.Conv2d(512, 512, 4, stride=2, padding=1)\n","        self.bn7 = nn.BatchNorm2d(512)\n","\n","        # Define decoder layers\n","        self.deconv1 = nn.ConvTranspose2d(512, 512, 4, stride=2, padding=1)\n","        self.bn8 = nn.BatchNorm2d(512)\n","        self.deconv2 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)\n","        self.bn9 = nn.BatchNorm2d(512)\n","        self.deconv3 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)\n","        self.bn10 = nn.BatchNorm2d(512)\n","        self.deconv4 = nn.ConvTranspose2d(1024, 512, 4, stride=2, padding=1)\n","        self.bn11 = nn.BatchNorm2d(512)\n","        self.deconv5 = nn.ConvTranspose2d(1024, 256, 4, stride=2, padding=1)\n","        self.bn12 = nn.BatchNorm2d(256)\n","        self.deconv6 = nn.ConvTranspose2d(512, 128, 4, stride=2, padding=1)\n","        self.bn13 = nn.BatchNorm2d(128)\n","        self.deconv7 = nn.ConvTranspose2d(256, 64, 4, stride=2, padding=1)\n","        self.bn14 = nn.BatchNorm2d(64)\n","        self.deconv8 = nn.ConvTranspose2d(128, 3, 4, stride=2, padding=1)\n","        \n","        # Define activation functions\n","        self.relu = nn.ReLU()\n","        self.lrelu = nn.LeakyReLU(0.2)\n","        self.sigmoid = nn.Sigmoid()\n","        \n","    def forward(self, x):\n","        # Encode\n","        enc1 = self.conv1(x)\n","        enc2 = self.bn2(self.conv2(self.relu(x)))\n","        enc3 = self.bn3(self.conv3(self.relu(enc2)))\n","        enc4 = self.bn4(self.conv4(self.relu(enc3)))\n","        enc5 = self.bn5(self.conv5(self.relu(enc4)))\n","        enc6 = self.bn6(self.conv6(self.relu(enc5)))\n","        enc7 = self.bn7(self.conv7(self.relu(enc6)))\n","            # Decode\n","        dec1 = self.deconv1(self.relu(enc7))\n","        dec1 = torch.cat([dec1, enc6], dim=1)\n","        dec1 = self.bn8(dec1)\n","        dec2 = self.deconv2(self.relu(dec1))\n","        dec2 = torch.cat([dec2, enc5], dim=1)\n","        dec2 = self.bn9(dec2)\n","        dec3 = self.deconv3(self.relu(dec2))\n","        dec3 = torch.cat([dec3, enc4], dim=1)\n","        dec3 = self.bn10(dec3)\n","        dec4 = self.deconv4(self.relu(dec3))\n","        dec4 = torch.cat([dec4, enc3], dim=1)\n","        dec4 = self.bn11(dec4)\n","        dec5 = self.deconv5(self.relu(dec4))\n","        dec5 = torch.cat([dec5, enc2], dim=1)\n","        dec5 = self.bn12(dec5)\n","        dec6 = self.deconv6(self.relu(dec5))\n","        dec6 = torch.cat([dec6, enc1], dim=1)\n","        dec6 = self.bn13(dec6)\n","        dec7 = self.deconv7(self.relu(dec6))\n","        dec7 = self.bn14(dec7)\n","        dec8 = self.deconv8(self.relu(dec7))\n","        out = self.sigmoid(dec8)\n","        return out\n","\n"],"metadata":{"id":"BbqWndz1pJFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CarrierSecretDataset(Dataset):\n","  def init(self, carrier_dir, secret_dir):\n","    self.carrier_files = sorted(os.listdir(carrier_dir))\n","    self.secret_files = sorted(os.listdir(secret_dir))\n","    self.carrier_dir = carrier_dir\n","    self.secret_dir = secret_dir\n","    \n","  def __len__(self):\n","    return len(self.carrier_files)\n","    \n","  def __getitem__(self, idx):\n","    carrier_file = os.path.join(self.carrier_dir, self.carrier_files[idx])\n","    secret_file = os.path.join(self.secret_dir, self.secret_files[idx])\n","    carrier_img = Image.open(carrier_file).convert('RGB')\n","    secret_img = Image.open(secret_file).convert('L')\n","    secret_img = wt2(secret_img)\n","    return carrier_img, secret_img\n"],"metadata":{"id":"UkKVgKqjpe7p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CarrierSecretDataset(train_carrier_dir, train_secret_dir)\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_dataset = CarrierSecretDataset(test_carrier_dir, test_secret_dir)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(unet.parameters(), lr=learning_rate)\n","for epoch in range(num_epochs):\n","  unet.train()\n","for i, (carriers, secrets) in enumerate(train_loader):\n","  carriers = carriers.to(device)\n","  secrets = secrets.to(device)\n","  optimizer.zero_grad()\n","  outputs = unet(carriers)\n","  loss = criterion(outputs, carriers)\n","  loss.backward()\n","  optimizer.step()\n","  \n","  if i % print_freq == 0:\n","      print('Epoch [{}/{}], Iter [{}/{}], Loss: {:.4f}'\n","            .format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n","\n","# Test\n","  unet.eval()\n","  with torch.no_grad():\n","      test_loss = 0.0\n","      for carriers, secrets in test_loader:\n","          carriers = carriers.to(device)\n","          secrets = secrets.to(device)\n","\n","          outputs = unet(carriers)\n","          test_loss += criterion(outputs, carriers).item() * carriers.size(0)\n","      \n","      test_loss /= len(test_loader.dataset)\n","      print('Test Loss: {:.4f}'.format(test_loss))\n","      \n","  # Save the model\n","  if (epoch+1) % save_freq == 0:\n","      model_path = os.path.join(model_dir, 'unet_epoch{}.pth'.format(epoch+1))\n","      torch.save(unet.state_dict(), model_path)\n","      print('Finished training the U-Net model.')\n","\n"],"metadata":{"id":"BPllo7nWpuaO"},"execution_count":null,"outputs":[]}]}