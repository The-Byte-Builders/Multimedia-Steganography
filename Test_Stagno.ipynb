{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1_CL8zSa_6IFBIdbwCxbPRpnZZ34CwTek","authorship_tag":"ABX9TyMEW8SlOTJieCSzcqjfFpw6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np \n","import pandas as pd\n","import torchvision\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import joblib\n","from google.colab import drive\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"],"metadata":{"id":"N3nkY1uft-Da"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root_dir = '/content/drive/MyDrive/Colab Notebooks/'\n","dataset_path = os.path.join(root_dir,'Steganography/Dataset')\n","\n","train_csv = os.path.join(root_dir,'train_dataset.csv')\n","valid_csv = os.path.join(root_dir,'validation_dataset.csv')\n","test_csv = os.path.join(dataset_path,'validation_dataset.csv')\n","train_folder = os.path.join(dataset_path,'train')\n","validation_folder = os.path.join(dataset_path,'valid')"],"metadata":{"id":"4LIuVA7HtmzO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class SteganoDataset(torch.utils.data.Dataset):\n","    def __init__(self,dataset_csv,transforms,type_of_dataset,size='complete'):\n","        self.dataset = pd.read_csv(dataset_csv)\n","        #self.dataset = dataset_csv\n","        self.dataset = self.dataset.reset_index(drop=True)\n","        if size !='complete':\n","            self.dataset = self.dataset[:2]\n","        self.transforms = transforms\n","        self.type = type_of_dataset\n","    \n","    def __getitem__(self,index):\n","        cover_image = self.dataset.iloc[index]['cover_image']\n","        secret_image = self.dataset.iloc[index]['secret_image']\n","        cover_image = Image.open(os.path.join(dataset_path,'train',cover_image))\n","        secret_image = Image.open(os.path.join(dataset_path,'train',secret_image))\n","        transformed_cover_image = self.transforms(cover_image)\n","        transformed_secret_image = self.transforms(secret_image)\n","        return {\n","                'cover_image':transformed_cover_image,\n","                'secret_image':transformed_secret_image,\n","            }\n","        \n","    \n","    def __len__(self):\n","      return len(self.dataset)"],"metadata":{"id":"GIW1ez_otZiA"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pOHTdzOVQaYp"},"outputs":[],"source":["class PrepNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=3,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=3,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","    \n","    def forward(self,secret_image):\n","        output_1 = F.relu(self.conv1(secret_image))\n","        output_2 = F.relu(self.conv2(secret_image))\n","        output_3 = F.relu(self.conv3(secret_image))\n","        \n","        concatenated_image = torch.cat([output_1,output_2,output_3],dim=1)\n","        output_4 = F.relu(self.conv4(concatenated_image))\n","        output_5 = F.relu(self.conv5(concatenated_image))\n","        output_6 = F.relu(self.conv6(concatenated_image))\n","        \n","        final_concat_image = torch.cat([output_4,output_5,output_6],dim=1)\n","        return final_concat_image\n","\n","class HidingNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=38,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=38,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=38,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv7 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv8 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv9 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.final_layer = nn.Conv2d(in_channels=35,out_channels=3,kernel_size=(3,3),stride=1,padding=1)\n","        \n","    def forward(self,secret_image,cover_image):\n","        concatenated_secrets = torch.cat([cover_image,secret_image],dim=1)\n","        \n","        output_1 = F.relu(self.conv1(concatenated_secrets))\n","        output_2 = F.relu(self.conv2(concatenated_secrets))\n","        output_3 = F.relu(self.conv3(concatenated_secrets))\n","        concat_1 = torch.cat([output_1,output_2,output_3],dim=1)\n","        \n","        output_4 = F.relu(self.conv4(concat_1))\n","        output_5 = F.relu(self.conv5(concat_1))\n","        output_6 = F.relu(self.conv6(concat_1))\n","        concat_2 = torch.cat([output_4,output_5,output_6],dim=1)\n","        \n","        output_7 = F.relu(self.conv7(concat_2))\n","        output_8 = F.relu(self.conv8(concat_2))\n","        output_9 = F.relu(self.conv9(concat_2))\n","        concat_3 = torch.cat([output_7,output_8,output_9],dim=1)\n","        output_converted_image = F.relu(self.final_layer(concat_3))\n","        \n","        return output_converted_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3Oh5jAVRKXg"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self,prep_network,hiding_network):\n","        super().__init__()\n","        self.prep_network = prep_network\n","        self.hiding_network = hiding_network\n","    \n","    def forward(self,cover_image,secret_image):\n","        encoded_secret_image = self.prep_network(secret_image)\n","        \n","        hidden_image = self.hiding_network(encoded_secret_image,\n","                                           cover_image\n","                                          )\n","#         hidden_image = (0.01**0.5)*torch.randn(hidden_image.size(),device=device)\n","        return hidden_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o8pOZbBYRxuX"},"outputs":[],"source":["class RevealNetwork(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv2 = nn.Conv2d(in_channels=3,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv3 = nn.Conv2d(in_channels=3,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv4 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv5 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv6 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        self.conv7 = nn.Conv2d(in_channels=35,out_channels=10,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv8 = nn.Conv2d(in_channels=35,out_channels=20,kernel_size=(3,3),stride=1,padding=1)\n","        self.conv9 = nn.Conv2d(in_channels=35,out_channels=5,kernel_size=(5,5),stride=1,padding=2)\n","        \n","        \n","        self.final_layer = nn.Conv2d(in_channels=35,out_channels=3,kernel_size=(3,3),stride=1,padding=1)    \n","    \n","    def forward(self,hidden_image):\n","        \n","        output_1 = F.relu(self.conv1(hidden_image))\n","        output_2 = F.relu(self.conv2(hidden_image))\n","        output_3 = F.relu(self.conv3(hidden_image))\n","        concat_1 = torch.cat([output_1,output_2,output_3],dim=1)\n","        \n","        output_4 = F.relu(self.conv4(concat_1))\n","        output_5 = F.relu(self.conv5(concat_1))\n","        output_6 = F.relu(self.conv6(concat_1))\n","        concat_2 = torch.cat([output_4,output_5,output_6],dim=1)\n","        \n","        output_7 = F.relu(self.conv7(concat_2))\n","        output_8 = F.relu(self.conv8(concat_2))\n","        output_9 = F.relu(self.conv9(concat_2))\n","        concat_3 = torch.cat([output_7,output_8,output_9],dim=1)\n","        \n","        \n","        output_revealed_image = F.relu(self.final_layer(concat_3))\n","        \n","        return output_revealed_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RZk4rMWrSPfG"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self,reveal_network):\n","        super().__init__()\n","        self.reveal_network = reveal_network\n","    \n","    def forward(self,hidden_image):\n","        reveal_image = self.reveal_network(hidden_image)\n","        return reveal_image"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hstt-fC5Sa1L"},"outputs":[],"source":["class SteganoModel(nn.Module):\n","    def __init__(self,encoder,decoder):\n","        super().__init__()\n","        self.encoder = encoder\n","        self.decoder = decoder\n","    \n","    def forward(self,cover_image,secret_image,hidden_image,mode):\n","        if mode == 'full':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = True\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            hidden_image = self.encoder(cover_image,secret_image)\n","            reveal_image = self.decoder(hidden_image)\n","            return hidden_image,reveal_image\n","        elif mode == 'encoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = False\n","            hidden_image = self.encoder(cover_image,secret_image)\n","            return hidden_image\n","        elif mode == 'decoder':\n","            for param in self.encoder.parameters():\n","                param.requires_grad = False\n","            for param in self.decoder.parameters():\n","                param.requires_grad = True\n","            \n","            reveal_image = self.decoder(hidden_image)\n","            return reveal_image"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":345},"id":"wLr8lY00tCtI","executionInfo":{"status":"error","timestamp":1672381559322,"user_tz":-345,"elapsed":4720,"user":{"displayName":"Biplov Karna","userId":"15195340363533863660"}},"outputId":"4172bb3a-c001-4c6f-eee4-bb1cef213dac"},"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9913ff8e89f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/Steganography/modeldummy.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# loaded_model = joblib.load(filename)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    787\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mUNSAFE_MESSAGE\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1129\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mfind_class\u001b[0;34m(self, mod_name, name)\u001b[0m\n\u001b[1;32m   1122\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mmod_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_module_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;31m# Load the data (which may in turn use `persistent_load` to load tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'SteganoModel' on <module '__main__'>"]}],"source":["import os\n","import torch\n","filename = os.path.join(\"/content/drive/MyDrive/Colab Notebooks/Steganography/modeldummy.pkl\")\n","# loaded_model = joblib.load(filename)\n","model = torch.load(filename)"]}]}